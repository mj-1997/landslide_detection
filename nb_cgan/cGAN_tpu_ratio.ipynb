{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cGAN_tpu_ratio.ipynb","private_outputs":true,"provenance":[{"file_id":"1eWTjtkJ3HxJaWO5S8VkYwzHy1khLMYOE","timestamp":1632301181055}],"collapsed_sections":["9LlN8wgNNclE","3-s8ZLiK1iGP","OX8_6AzmyZCg","hwdlxLDjFFAn","ZsYPff9FaCw8","tSWHwINs1z9u","hziMkmBc1nYP"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9LlN8wgNNclE"},"source":["##Start up"]},{"cell_type":"markdown","metadata":{"id":"nG2A_pxD1fXN"},"source":["### GDrive"]},{"cell_type":"code","metadata":{"id":"HvA6uejaN4aA"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3-s8ZLiK1iGP"},"source":["### Enable TPU\n","Edit --> Notebook Settings --> TPU\n","Then check if TPU works"]},{"cell_type":"markdown","metadata":{"id":"8L_G9P3QHMFM"},"source":["Ensure that the number of instances is perfectly divisible by the steps_per_epoch parameter so that all the instances are used during\n","training. For example, we have 60000 instances in our training set. 60000\n","is divisible by 50 so that means all our instances are fed into the model without any leftovers. If you hit run, it should start training on a TPU instance after a short while:\n","\n","\n","Basically should have that data is 256 all the time in batch not a leftover with less... Could get rid of the data that does not fit into it?"]},{"cell_type":"code","metadata":{"id":"uNkSvTzz1tde"},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","print(\"Tensorflow version \" + tf.__version__)\n","\n","try:\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n","except ValueError:\n","  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n","\n","tf.config.experimental_connect_to_cluster(tpu)\n","tf.tpu.experimental.initialize_tpu_system(tpu)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xF0zrSmSfTO-"},"source":["#This strategy ssems to not work?\n","\n","# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","tpu_strategy = tf.distribute.TPUStrategy(tpu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"up3WB1dw1xnl"},"source":["### Import lib"]},{"cell_type":"code","metadata":{"id":"Zhi-IN5jWgwn"},"source":["#Genna\n","!pip install -q segmentation_models\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8v_0K5UScc4v"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2VBCw6Pxchlz"},"source":["print (tf.version)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dbpBqfskr2t1"},"source":["from segmentation_models.losses import binary_focal_dice_loss #this also exists.."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8oH6wjh1ojF6"},"source":["from segmentation_models.losses import bce_dice_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_52JyrAHNhH2"},"source":["import os\n","import glob\n","import numpy as np\n","import pandas as pd\n","# import tensorflow as tf\n","import pathlib\n","import re\n","import random\n","from tqdm.notebook import tqdm\n","import math\n","# import itertools\n","import time\n","# from sklearn.metrics import confusion_matrix\n","# from sklearn.metrics import classification_report\n","# import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9g6c-bTchAic"},"source":["\n","import matplotlib.pyplot as plt\n","plt.style.use(\"ggplot\")\n","%matplotlib inline\n","\n","from tqdm import tqdm_notebook, tnrange\n","from itertools import chain\n","from skimage.io import imread, imshow, concatenate_images\n","from skimage.transform import resize\n","from skimage.morphology import label\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","\n","from keras.models import Model, load_model\n","from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n","from keras.layers.core import Lambda, RepeatVector, Reshape\n","from keras.layers.convolutional import Conv2D, Conv2DTranspose\n","from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n","from keras.layers.merge import concatenate, add\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","# from keras.optimizers import Adam #worked before since 19-08-2021 doesnt work anymore so now import via tf\n","from tensorflow.keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJQdQboBS7HD"},"source":["\n","from skimage.io import imread\n","from skimage.transform import resize\n","# from keras.models import Sequence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CgDrqIr_mn7B"},"source":["from numpy import load\n","from numpy import zeros\n","from numpy import ones\n","from numpy.random import randint\n","# from keras.optimizers import Adam\n","from keras.initializers import RandomNormal\n","from keras.models import Model\n","from keras.models import Input\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from keras.layers import Dropout\n","from keras.layers import BatchNormalization\n","from keras.layers import LeakyReLU\n","# from matplotlib import pyplot\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5f8b5eMXOmjD"},"source":["import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OX8_6AzmyZCg"},"source":["## Choose properties"]},{"cell_type":"code","metadata":{"id":"9xpxFYkXjSlR"},"source":["# global parameters\n","P = {\n","\n","    'SEED': 42,\n","     \n","    # image size to sample\n","    # 'SIZE': 160, \n","    # 'SIZE': 224, \n","     'SIZE': 256, \n","    # 'SIZE': 320,\n","    # 'BATCH_SIZE': 32 * strategy.num_replicas_in_sync, #256.. 64 is 512. \n","    \n","    # 'FOLDS': 5,\n","    \n","    # 'LEARNING_RATE': 0.00075,\n","    \n","    'EPOCHS': 100,\n","     \n","    # 'VERSION': 'v6'\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d0ZaEuh2ycCP"},"source":["n_batch = 64\n","num_epochs = 100 #200 in og pix2pix recommended\n","path_base = \"/content/drive/MyDrive/Thesis/dif_incl_mask_v3/\" #v3 is with -0.8,0.8\n","# os.makedirs(path_base)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HFXKXKjFh97i"},"source":["version = \"attempt_1_0710_bcedice_bsize_\" + str(n_batch) + \"/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uao7QnxHyuTx"},"source":["path_results = path_base + \"results/\" + version\n","os.makedirs(path_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6byztb7Eyr_b"},"source":["path_to_save = path_base + \"models/\" + version\n","os.makedirs(path_to_save)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xo1B97qumulL"},"source":["path_results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wwPLPIGLm31l"},"source":["path_to_save"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KHM-Arpm-I3o"},"source":["def remove_files(dir):\n","  for f in os.listdir(dir):\n","      os.remove(os.path.join(dir, f))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixs7bTI3-TaS"},"source":["# remove_files(path_to_save)\n","# remove_files(path_results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_s19EohvZpJR"},"source":["!ls -la {path_to_save}\n","!ls -la {path_results}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MnasP0Na_kvs"},"source":["files from kaggle"]},{"cell_type":"code","metadata":{"id":"Q-8L8xSarfvM"},"source":["tfrec_files_train = tf.io.gfile.glob('gs://kds-4a817e787c8a7fee3ad00543d64eebbf33a868ce7af53de4fbb340ef/*')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR-32_xRbs22"},"source":["tfrec_files_val= tf.io.gfile.glob('gs://kds-54c443e29c2dd043ed5923b96618f7c925f9492d97976baff14524fc/*')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jm0tFLGfv9x_"},"source":["# tfrec_files_test = tf.io.gfile.glob('gs://kds-fb4c9db2eeda8b5477c4a6f6c0060aff5b6e581e9a031e7936b918cf/*')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"07YnnkRINOgH"},"source":["len_files_to_shuffle = (len(tfrec_files_train)) * 100\n","len_files_to_shuffle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eACO6VseNOgH"},"source":["len_files_val_to_shuffle = (len(tfrec_files_val)) * 100\n","len_files_val_to_shuffle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j1sebbhzBQCz"},"source":["tfrec_files_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HdfcRyiVBR39"},"source":["tfrec_files_val"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fNjCWByL3crG"},"source":["Can make the val dataset exactly as long as the batch size? such that there is no small remainder? No there are only 100..."]},{"cell_type":"markdown","metadata":{"id":"hwdlxLDjFFAn"},"source":["#CGAN\n","https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/"]},{"cell_type":"markdown","metadata":{"id":"j07yi4A19cH8"},"source":["Alternative ; https://www.tensorflow.org/tutorials/generative/pix2pix#training"]},{"cell_type":"markdown","metadata":{"id":"sQXsAnx0k6AM"},"source":["## Define cGAN"]},{"cell_type":"code","metadata":{"id":"os9ksgTRTnrl"},"source":["# define the discriminator model\n","def define_discriminator(image_shape,image_shape_target):\n","\t# weight initialization\n","\tinit = RandomNormal(stddev=0.02)\n","\t# source image input\n","\tin_src_image = Input(shape=image_shape)\n","\t# target image input\n","\tin_target_image = Input(shape=image_shape_target)\n","\t# concatenate images channel-wise\n","\tmerged = Concatenate()([in_src_image, in_target_image])\n","\t# C64\n","\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# C128\n","\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","\td = BatchNormalization()(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# C256\n","\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","\td = BatchNormalization()(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# C512\n","\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","\td = BatchNormalization()(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# second last output layer\n","\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n","\td = BatchNormalization()(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# patch output\n","\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n","\tpatch_out = Activation('sigmoid')(d)\n","\t# define model\n","\tmodel = Model([in_src_image, in_target_image], patch_out)\n","\t# compile model\n","\topt = Adam(learning_rate=0.0002, beta_1=0.5) #lr\n","  \n","  # opt = Adam(learning_rate=0.0002, beta_1=0.5)\n","\t# model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n","\tmodel.compile(loss = bce_dice_loss, optimizer=opt, loss_weights=[0.5])\n","  # model.compile(loss= binary_focal_dice_loss, optimizer=opt, loss_weights=[0.5]) #binary_focal_dice #metrics toevoegen as metrics = []\n","  \n","\n","\n","\treturn model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"avgPqSk1fTrV"},"source":["\n","# define an encoder block\n","def define_encoder_block(layer_in, n_filters, batchnorm=True):\n","\t# weight initialization\n","\tinit = RandomNormal(stddev=0.02)\n","\t# add downsampling layer\n","\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n","\t# conditionally add batch normalization\n","\tif batchnorm:\n","\t\tg = BatchNormalization()(g, training=True)\n","\t# leaky relu activation\n","\tg = LeakyReLU(alpha=0.2)(g)\n","\treturn g\n","\n","# define a decoder block\n","def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n","\t# weight initialization\n","\tinit = RandomNormal(stddev=0.02)\n","\t# add upsampling layer\n","\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n","\t# add batch normalization\n","\tg = BatchNormalization()(g, training=True)\n","\t# conditionally add dropout\n","\tif dropout:\n","\t\tg = Dropout(0.5)(g, training=True)\n","\t# merge with skip connection\n","\tg = Concatenate()([g, skip_in])\n","\t# relu activation\n","\tg = Activation('relu')(g)\n","\treturn g\n","\n","# define the standalone generator model\n","def define_generator(image_shape=(256,256,1)):\n","\t# weight initialization\n","\tinit = RandomNormal(stddev=0.02)\n","\t# image input\n","\tin_image = Input(shape=image_shape)\n","\t# encoder model\n","\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n","\te2 = define_encoder_block(e1, 128)\n","\te3 = define_encoder_block(e2, 256)\n","\te4 = define_encoder_block(e3, 512)\n","\te5 = define_encoder_block(e4, 512)\n","\te6 = define_encoder_block(e5, 512)\n","\te7 = define_encoder_block(e6, 512)\n","\t# bottleneck, no batch norm and relu\n","\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n","\tb = Activation('relu')(b)\n","\t# decoder model\n","\td1 = decoder_block(b, e7, 512)\n","\td2 = decoder_block(d1, e6, 512)\n","\td3 = decoder_block(d2, e5, 512)\n","\td4 = decoder_block(d3, e4, 512, dropout=False)\n","\td5 = decoder_block(d4, e3, 256, dropout=False)\n","\td6 = decoder_block(d5, e2, 128, dropout=False)\n","\td7 = decoder_block(d6, e1, 64, dropout=False)\n","\t# output, 1 band without dummy\n","\tg = Conv2DTranspose(1, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n","\tout_image = Activation('tanh')(g) #change to sigmoid, then will be between 0 and 1 perfect for binary. But pix2pix says tanh\n","\t# define model\n","\tmodel = Model(in_image, out_image)\n","\treturn model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XIwgKZH_pJuC"},"source":["\n","# define the combined generator and discriminator model, for updating the generator\n","def define_gan(g_model, d_model, image_shape):\n","\t# make weights in the discriminator not trainable\n","\tfor layer in d_model.layers:\n","\t\tif not isinstance(layer, BatchNormalization):\n","\t\t\tlayer.trainable = False\n","\t# define the source image\n","\tin_src = Input(shape=image_shape)\n","\t# connect the source image to the generator input\n","\tgen_out = g_model(in_src)\n","\t# connect the source input and generator output to the discriminator input\n","\tdis_out = d_model([in_src, gen_out])\n","\t# src image as input, generated image and classification output\n","\tmodel = Model(in_src, [dis_out, gen_out])\n","\t# compile model\n","\topt = Adam(learning_rate=0.0002, beta_1=0.5)\n","  # opt = Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss=[bce_dice_loss, 'mae'], optimizer=opt, loss_weights=[1,100]) #binary_focal_dice\n","\treturn model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HlJjFmdufXDX"},"source":["## Load performance / Save model"]},{"cell_type":"code","metadata":{"id":"VwN0I-lcajsg"},"source":["# for x1,x2 in train_dataset:\n","#   print(x1.shape,x2.shape)\n","#   for i in range(3):\n","#     print(x.shape)\n","#     tar = x2[i,:,:,0]\n","#     src = x1[i,:,:,0]\n","#     print(src.shape,tar.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CusFx_KcB9Yb"},"source":["# #its not giving 3 images though!\n","# def save_images(source,target,gen_target,file_path_to_save,step,n_samples = 3):\n","#   #plot source im\n","#   for i in range(n_samples):\n","#     src = source[i,:,:,0]\n","#     plt.subplot(3, n_samples, 1 + i)\n","#     plt.axis('off')\n","#     plt.imshow(src)\n","# \t# plot generated target image\n","#   for i in range(n_samples):\n","#     gen_tar = gen_target[i,:,:,0]\n","#     plt.subplot(3, n_samples, 1 + n_samples + i)\n","#     plt.axis('off')\n","#     plt.imshow(gen_tar)\n","# \t# plot real target images\n","#   for i in range(n_samples):\n","#     tar = target[i,:,:,0]\n","#     plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n","#     plt.axis('off')\n","#     plt.imshow(tar)\n","# \t# save plot to file\n","#   filename1 = 'plot_%06d.png' % (step+1)\n","#   plt.savefig(file_path_to_save + filename1)\n","#   plt.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dkj0Nj3Hwbv9"},"source":["#its not giving 3 images though!\n","def save_images(source,target,gen_target,file_path_to_save,step,n_samples = 3):\n","  #plot source im\n","  for i in range(n_samples):\n","    #so these are scaled, aka not originals\n","    src = source[i,:,:,0]\n","    gen_tar = gen_target[i,:,:,0]\n","    tar = target[i,:,:,0]\n","    images = [src,gen_tar,tar]\n","    titles = [\"source\",\"generated target\",\"true target\"]\n","\n","    f = plt.figure()\n","    f.add_subplot(1,3, 1)\n","    plt.title(titles[0])\n","    plt.imshow(images[0])\n","    plt.axis('off')\n","    \n","    \n","    f.add_subplot(1,3, 2)\n","    plt.title(titles[1])\n","    plt.imshow(images[1])\n","    plt.axis('off')\n","\n","    f.add_subplot(1,3, 3)\n","    plt.title(titles[2])\n","    plt.imshow(images[2])\n","    plt.axis('off')\n","\n","    filename1 = 'plot_s%i_%06d.png' % (i,step+1)\n","    plt.savefig(file_path_to_save + filename1)\n","    plt.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dH4dwMkdcAh-"},"source":["\n","def save_model(file_path_to_save,model_name,model,step):\n","  filename = file_path_to_save + model_name + '__%s.h5' % (step+1)\n","  model.save(filename,include_optimizer = True) \n","  print('>Saved model: %s ' % (filename))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YmyoOvijS5kZ"},"source":["Do a iou per epoch, and plot some specific images"]},{"cell_type":"code","metadata":{"id":"VfSpIzz7uanZ"},"source":["def iou_coe(output, target, axis,threshold=0.0, smooth=1e-5):\n","# def iou_coe(output, target, threshold=0.0, axis=(1,2,3), smooth=1e-5):\n","    \"\"\"\" With tanh threshold = 0.0\n","    \"\"\" \n","\n","    \"\"\"Non-differentiable Intersection over Union (IoU) for comparing the\n","    similarity of two batch of data, usually be used for evaluating binary image segmentation.\n","    The coefficient between 0 to 1, and 1 means totally match.\n","\n","    Parameters\n","    -----------\n","    output : tensor\n","        A batch of distribution with shape: [batch_size, ....], (any dimensions).\n","    target : tensor\n","        The target distribution, format the same with `output`.\n","    threshold : float\n","        The threshold value to be true.\n","    axis : tuple of integer\n","        All dimensions are reduced, default ``(1,2,3)``.\n","    smooth : float\n","        This small value will be added to the numerator and denominator, see ``dice_coe``.\n","\n","    Notes\n","    ------\n","    - IoU cannot be used as training loss, people usually use dice coefficient for training, IoU and hard-dice for evaluating.\n","\n","    \"\"\"\n","    pre = tf.cast(output > threshold, dtype=tf.float32)\n","    truth = tf.cast(target > threshold, dtype=tf.float32)\n","    inse = tf.reduce_sum(tf.multiply(pre, truth), axis=axis)  # AND\n","    union = tf.reduce_sum(tf.cast(tf.add(pre, truth) >= 1, dtype=tf.float32), axis=axis)  # OR\n","    # old axis=[0,1,2,3]\n","    # epsilon = 1e-5\n","    # batch_iou = inse / (union + epsilon)\n","    # new haodong\n","    batch_iou = (inse + smooth) / (union + smooth)\n","    iou = tf.reduce_mean(batch_iou, name='iou_coe')\n","    return iou  # , pre, truth, inse, union"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qodGXRt8T-wY"},"source":["def dice_hard_coe(output, target,  axis, threshold=0.0,smooth=1e-5):\n","# def dice_hard_coe(output, target, threshold=0.0, threshold_to_target = 0.0, axis=(1, 2, 3), smooth=1e-5):\n","\n","    \"\"\"\" With tanh threshold = 0.0\n","    \"\"\" \n","\n","\n","    \"\"\"Non-differentiable Sørensen–Dice coefficient for comparing the similarity\n","    of two batch of data, usually be used for binary image segmentation i.e. labels are binary.\n","    The coefficient between 0 to 1, 1 if totally match.\n","\n","    Parameters\n","    -----------\n","    output : tensor\n","        A distribution with shape: [batch_size, ....], (any dimensions).\n","    target : tensor\n","        The target distribution, format the same with `output`.\n","    threshold : float\n","        The threshold value to be true.\n","    axis : tuple of integer\n","        All dimensions are reduced, default ``(1,2,3)``.\n","    smooth : float\n","        This small value will be added to the numerator and denominator, see ``dice_coe``.\n","\n","    References\n","    -----------\n","    - `Wiki-Dice <https://en.wikipedia.org/wiki/Sørensen–Dice_coefficient>`__\n","\n","    \"\"\"\n","\n","\n","\n","    output = tf.cast(output > threshold, dtype=tf.float32)\n","    target = tf.cast(target > threshold, dtype=tf.float32) \n","    inse = tf.reduce_sum(tf.multiply(output, target), axis=axis)\n","    l = tf.reduce_sum(output, axis=axis)\n","    r = tf.reduce_sum(target, axis=axis)\n","    # old axis=[0,1,2,3]\n","    # hard_dice = 2 * (inse) / (l + r)\n","    # epsilon = 1e-5\n","    # hard_dice = tf.clip_by_value(hard_dice, 0, 1.0-epsilon)\n","    # new haodong\n","    hard_dice = (2. * inse + smooth) / (l + r + smooth)\n","    ##\n","    hard_dice = tf.reduce_mean(hard_dice, name='hard_dice')\n","    return hard_dice\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2b8xjccbSfDD"},"source":["## Defs of load_samples"]},{"cell_type":"code","metadata":{"id":"bLHaXGk6Jyum"},"source":["\n","# select a batch of random samples, returns images and target\n","def generate_real_samples(batch):\n","  # unpack dataset\n","  X1,X2 = batch\n","  n_samples = X1.shape[0] \n","\t# generate 'real' class labels (1)\n","  #patch_shape is a constant\n","  y = ones((n_samples, patch_shape, patch_shape, 1))\n","  return [X1, X2], y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xoQD6AwJz4R"},"source":["# generate a batch of images, returns images and targets\n","def generate_fake_samples(g_model, samples):\n","\t# generate fake instance\n","\tX = g_model.predict(samples)\n","\t# create 'fake' class labels (0)\n","\ty = zeros((len(X), patch_shape, patch_shape, 1))\n","\treturn X, y\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WxO0Um-1aRuk"},"source":["## Run GAN model\n","Here need to define that you use TPU\n"]},{"cell_type":"code","metadata":{"id":"wzqyd-_8SsxL"},"source":["\n","image_shape = (256,256,1)\n","image_shape_target = (256,256,1) #needs to be 256,256,1 not 256,256!\n","\n","\n","# image_shape = (256,256,2)\n","# image_shape_target = (256,256,1) #needs to be 256,256,1 not 256,256!\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwstExFrJN39"},"source":["with tpu_strategy.scope():\n","  d_model = define_discriminator(image_shape,image_shape_target)\n","  g_model = define_generator(image_shape)\n","  gan_model = define_gan(g_model,d_model,image_shape) \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DBC4HB-Hbal-"},"source":["patch_shape = d_model.output_shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbitBNub6hxU"},"source":["d_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvShBjFN6Wht"},"source":["g_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JTOnq4r66kBx"},"source":["gan_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G0GDe6O-vOgA"},"source":["# TF dataset"]},{"cell_type":"markdown","metadata":{"id":"-HK0MyhSxRQ3"},"source":["https://www.kaggle.com/docs/tpu\n","Could add some smart things from here"]},{"cell_type":"markdown","metadata":{"id":"WWwkL2qlXcVd"},"source":["## Parse and decode tfrec"]},{"cell_type":"code","metadata":{"id":"cliWhB1oEwhI"},"source":["#uncomment for A_ratio representation\n","\n","def parse_record(record):\n","  tfrecord_format = {\n","    \"x\": tf.io.FixedLenFeature([],tf.string),\n","    \"Y\": tf.io.FixedLenFeature([],tf.string)\n","    }\n","  return tf.io.parse_single_example(record, tfrecord_format) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3FAXFnA1ll2"},"source":["dim = 256"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ha4CpsIlHXoP"},"source":["#uncomment for A_ratio representation\n","def decode_record(record):\n","\n","  record_parsed = parse_record(record)\n","  # dataType = float32\n","  x = tf.io.decode_raw(\n","      record_parsed['x'],out_type = float\n","  )\n","  y = tf.io.decode_raw(\n","      record_parsed['Y'],out_type = float      \n","  )\n","\n","\n","  image_x = tf.reshape(x,(dim,dim,1))\n","  image_y = tf.reshape(y,(dim,dim,1))\n","\n","\n","\n","  return image_x,image_y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qxQxiEf3Fv9a"},"source":["# uncomment for ratioslope representation\n","\n","# def parse_record(record):\n","#   tfrecord_format = {\n","#     \"x\": tf.io.FixedLenFeature([],tf.string),\n","#     \"Y\": tf.io.FixedLenFeature([],tf.string),\n","#     \"dem\": tf.io.FixedLenFeature([],tf.string)\n","#     }\n","#   return tf.io.parse_single_example(record, tfrecord_format) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EGaUCHg5Fv9f"},"source":["# dim = 256"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uoPfKxsfFv9g"},"source":["# uncomment for ratioslope representation\n","# def decode_record(record):\n","\n","#   record_parsed = parse_record(record)\n","#   # dataType = float32\n","#   x = tf.io.decode_raw(\n","#       record_parsed['x'],out_type = float\n","#   )\n","#   y = tf.io.decode_raw(\n","#       record_parsed['Y'],out_type = float      \n","#   )\n","#   dem = tf.io.decode_raw(\n","#       record_parsed['dem'],out_type=float\n","#   )\n","\n","\n","#   image_x = tf.reshape(x,(dim,dim))\n","#   image_y = tf.reshape(y,(dim,dim,1))\n","#   image_dem = tf.reshape(dem,(dim,dim))\n","\n","#   image_x_stack = tf.stack((image_x,image_dem),axis = -1)\n","\n","\n","\n","#   return image_x_stack,image_y\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZsYPff9FaCw8"},"source":["## Add augmentations"]},{"cell_type":"code","metadata":{"id":"-0yT8n-oaFF9"},"source":["def dropout(image, size=256, p = 0.75, ct = 12, sz = 0.05):\n","    # input - one image of size [size, size, 3] not a batch of [b, size, size, 3]\n","    # output - image with ct squares of side size sz*size removed\n","    p = tf.cast(tf.random.uniform([],0,1) < p, tf.int32)\n","    if (p == 0)|(ct == 0)|(sz == 0): return image\n","\n","    for k in range(ct):\n","        # choose random location\n","        x = tf.cast(tf.random.uniform([], 0, size),tf.int32)\n","        y = tf.cast(tf.random.uniform([], 0, size),tf.int32)\n","        \n","        # compute square\n","        width = tf.cast(sz*size, tf.int32)*p\n","        ya = tf.math.maximum(0, y-width//2)\n","        yb = tf.math.minimum(size, y+width//2)\n","        xa = tf.math.maximum(0, x-width//2)\n","        xb = tf.math.minimum(size, x+width//2)\n","        \n","        # dropout image\n","        one = image[ya:yb, 0:xa, :]\n","        two = tf.zeros([yb-ya, xb-xa, image.shape[-1]]) \n","        three = image[ya:yb, xb:size, :]\n","        middle = tf.concat([one, two, three], axis=1)\n","        image = tf.concat([image[0:ya, :, :], middle, image[yb:size, :, :]], axis=0)\n","\n","    return image\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLxgUANfbMkQ"},"source":["\n","def augment(image, mask, seed=P['SEED'],size=P['SIZE']): #not sure if input image,mask is okinstead of record..\n","    # Flip\n","    if tf.random.uniform([], seed=seed) > 0.5:\n","        image = tf.image.flip_left_right(image)\n","        mask = tf.image.flip_left_right(mask)\n","\n","    if tf.random.uniform([],seed=seed) > 0.5:\n","        image = tf.image.flip_up_down(image)\n","        mask = tf.image.flip_up_down(mask)\n","        \n","    if tf.random.uniform([],seed=seed) > .75:\n","        image = tf.image.transpose(image)\n","        mask = tf.image.transpose(mask)\n","      \n","    p_rotate = tf.random.uniform([],seed=seed)\n","    if p_rotate > .75:\n","        image = tf.image.rot90(image, k=3) # rotate 270º\n","        mask = tf.image.rot90(mask, k=3)\n","    elif p_rotate > .5:\n","        image = tf.image.rot90(image, k=2) # rotate 180º\n","        mask = tf.image.rot90(mask, k=2)\n","    elif p_rotate > .25:\n","        image = tf.image.rot90(image, k=1) # rotate 90º\n","        mask = tf.image.rot90(mask, k=1)\n","        \n","    # Drop out. Only for the image with 3 bands\n","    # image = dropout(image, size, p=1.0, ct=10, sz=0.1)\n","                \n","    \n","    \n","    return image, mask\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tSWHwINs1z9u"},"source":["## Create data set from tfrec"]},{"cell_type":"code","metadata":{"id":"vFqvSRdZbhNP"},"source":["AUTO = tf.data.AUTOTUNE\n","ignore_order = tf.data.Options()\n","ignore_order.experimental_deterministic = False\n","\n","def get_training_dataset(files, len_shuffle,seed=P['SEED'], batch_size=n_batch):\n","    dataset = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n","    dataset = dataset.with_options(ignore_order)\n","    dataset = dataset.cache()\n","    dataset = dataset.repeat(2)\n","    dataset = dataset.map(lambda ex: decode_record(ex), num_parallel_calls=AUTO)\n","    dataset = dataset.map(augment, num_parallel_calls=AUTO) #maybe should do lambda x y here..\n","    dataset = dataset.shuffle(buffer_size= len_shuffle, seed=seed) #when shuffle??\n","    dataset = dataset.batch(batch_size, drop_remainder=False) #bc seconde one is only 16 for bsize 512.\n","    dataset = dataset.prefetch(AUTO)\n","    \n","    return dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZIL-xg_csH0K"},"source":["def count_examples(filenames):\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(str(filename)).group(1)) for filename in filenames]\n","    \n","    return np.sum(n)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KWsJesJ9oL6Q"},"source":["##somehow this function doesnt work.. maybe bc drop remainder!!!! --> bc val ls < batch size \n","def get_validation_dataset(files, len_shuffle,ordered=True,seed=P['SEED'], batch_size=n_batch):\n","    dataset = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n","    dataset = dataset.with_options(ignore_order)\n","    dataset = dataset.cache()\n","    # dataset = dataset.map(lambda ex: decode_record(ex), num_parallel_calls=AUTO)\n","    dataset = dataset.map(decode_record, num_parallel_calls=AUTO)\n","    dataset = dataset.shuffle(buffer_size = len_shuffle, seed=seed) \n","    dataset = dataset.batch(batch_size, drop_remainder=False)\n","    dataset = dataset.prefetch(AUTO)\n","\n","    return dataset\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qdbGCQw_KU9L"},"source":["## get Kaggle gs, create ds"]},{"cell_type":"markdown","metadata":{"id":"qWOH-_par1p7"},"source":["for training set"]},{"cell_type":"code","metadata":{"id":"1Zoh5bHkjnJ4"},"source":["\n","train_dataset = get_training_dataset(tfrec_files_train,len_files_to_shuffle)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pc5p6yQNrQXO"},"source":["val_dataset = get_validation_dataset(tfrec_files_val,len_files_val_to_shuffle) \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"grzciea8fRFO"},"source":["### Check if correct"]},{"cell_type":"code","metadata":{"id":"uV8Ojsa_pV0q"},"source":["#dropout in every image?? Lets try without first\n","def check_y(ds):\n","  for [x1,x2] in ds.take(1):\n","    tar = x2[:,:,:,0]\n","    src = x1[:,:,:,0]\n","\n","    print(tar.shape)\n","    print(src.shape)\n","    print(x1.shape)\n","    print(x2.shape)\n","    for i in range(tar.shape[0]):\n","    # for i in range(10):\n","      # plt.imshow(b1[i])\n","      # plt.axis('off')\n","      # plt.show()\n","      # plt.close()\n","      # plt.imshow(b2[i])\n","      # plt.axis('off')\n","      # plt.show()\n","      # plt.close()\n","      # plt.imshow(dem[i])\n","      # plt.axis('off')\n","      # plt.show()\n","      # plt.close()\n","      plt.imshow(tar[i])\n","      plt.axis('off')\n","      plt.show()\n","      plt.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g0MdT_sWkIe6"},"source":["check_y(val_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4KDRMeEkHzc"},"source":["check_y(train_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"01mSxi2b0D8y"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"yPWbTv0q4t_k"},"source":["## Train"]},{"cell_type":"markdown","metadata":{"id":"cW_KLvcaWIIO"},"source":["Maybe add some stuff to stop training if model is shit -->\n","- if iou and dice of test are still nan after >10 epochs\n","- if loss of dis. is still 0/close to 0 after>10 epochs (gan converge failure)\n"]},{"cell_type":"markdown","metadata":{"id":"XecLsuRxCOZl"},"source":["https://machinelearningmastery.com/practical-guide-to-gan-failure-modes/\n","\n","The loss is reported each training iteration, including the discriminator loss on real examples (d1), discriminator loss on generated or fake examples (d2), and generator loss, which is a weighted average of adversarial and L1 loss (g).\n","\n","\n","This is important. A stable GAN will have a discriminator loss around 0.5, typically between 0.5 and maybe as high as 0.7 or 0.8. The generator loss is typically higher and may hover around 1.0, 1.5, 2.0, or even higher\n","\n","This is an example of the normal or expected loss during training. Namely, discriminator loss for real and fake samples is about the same at or around 0.5, and loss for the generator is slightly higher between 0.5 and 2.0\n","\n","So quit training after x epochs if d1 and/or d2 loss is close to 0. Also if iou remains nan.."]},{"cell_type":"markdown","metadata":{"id":"mrgO_q6beGnw"},"source":["Acutally its possible to directly do iou over batch instead of in for loop I think..."]},{"cell_type":"code","metadata":{"id":"ZevmeGRAoG4Q"},"source":["path_to_save"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZwG54FuoIhl"},"source":["path_results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gkXaRCgmXdPp"},"source":["num_epochs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZ1eRiF6Zi0f"},"source":["#  def train(batch_train,batch_test,d_model=d_model, g_model=g_model, gan_model=gan_model,num_epochs = num_epochs,epoch_stop =30,epoch_save=[49,99] ,file_path_to_save_model=path_to_save,file_path_to_save_result=path_results):\n","\n","#   \"\"\"\" train model\n","#   Here also loss is calculated\n","#   Also stops after dloss remains low and/or iou remains nan (aka 0/x ? what gives a nan value? )\n","#   Here only the iou and dice for the positive images is calculated\n","#   batch_train: the train dataset, tfrecord dataset which is batched\n","#   batch_test: the test dataset, tfrecord dataset which is batched, only ls images\n","#   No if condition on validation set since the validation is only ls images\n","#   \"\"\"\"\"\n","  \n","#   #dice and iou over epochs for train and test set.\n","#   iou_over_epochs,iou_test_over_epochs = list(), list()\n","#   d1_hist, d2_hist, g_hist = list(), list(), list()\n","\n","#   for epoch in tqdm(range(num_epochs)):\n","\n","#     #metric per image over all image in one epoch\n","#     iou_over_epoch,iou_test_over_epoch = list(), list()\n","#     d1_epoch, d2_epoch, g_epoch = list(),list(),list()\n","\n","#     for [x1,x2] in tqdm(batch_train):\n","\n","#       # select a batch of real samples\n","#       [src, target], y_real = generate_real_samples([x1,x2]) \n","#       # generate a batch of fake samples\n","#       gen_target, y_fake = generate_fake_samples(g_model, src)  \n","#       # update discriminator for real samples\n","#       d_loss1 = d_model.train_on_batch([src,target], y_real)\n","#        # update discriminator for generated samples\n","#       d_loss2 = d_model.train_on_batch([src, gen_target], y_fake)\n","#       # update the generator\n","#       g_loss, _, _ = gan_model.train_on_batch(src, [y_real, target])\n","\n","      \n","#       #get 0 band!\n","#       iou_over_batch = iou_coe(gen_target[:,:,:,0],target[:,:,:,0],axis=(1,2))\n","\n","#       #record loss history, to get a plot of converging (hopefully) dis & gen loss over epochs (only for train ds(?))\n","#       d1_epoch.append(d_loss1)\n","#       d2_epoch.append(d_loss2)\n","#       g_epoch.append(g_loss)\n","  \n","      \n","#       #save iou\n","#       iou_over_epoch.append(iou_over_batch)\n","\n","#       if ((epoch+1) % 10 == 0):\n","#         save_images(src,target,gen_target,file_path_to_save_result,epoch)\n","\n","\n","# #retracing might be bc the batch_test has other size bc its smaller, so dif batch sizes..\n","#     for [x1,x2] in tqdm(batch_test):\n","#       target_pred = g_model.predict(x1)\n","#       iou_test = iou_coe(target_pred[:,:,:,0],x2[:,:,:,0],axis=(1,2))\n","#       #save iou\n","#       iou_test_over_epoch.append(iou_test)\n","\n","\n","#     #  #save the metric accross epochs.\n","#     iou_test_over_epochs.append(tf.reduce_mean(iou_test_over_epoch))\n","#     #save the metric accross epochs, for train\n","#     iou_over_epochs.append(tf.reduce_mean(iou_over_epoch))\n","         \n","\n","#     # out of batch loop, in epoch loop\n","#     # record history over epochs --> could either do mean of each epoch or just leave them for each batch.\n","#     d1_hist.append(d1_epoch)\n","#     d2_hist.append(d2_epoch)\n","#     g_hist.append(g_epoch)\n","\n","    \n","#     if tf.equal(epoch,epoch_stop): #this works!\n","#       print('d loss at epoch stop',d_loss1)\n","#       # print(d_loss1 == np.nan)\n","#       # print(d_loss1 == float('nan'))\n","\n","#       if tf.math.less(d_loss1,tf.constant(0.01)):\n","#         print('then should quit since d1 loss is close to zero:',d_loss1) #works\n","#         # break\n","#       elif np.isnan(d_loss1):\n","#         print(\"its nan\")\n","#         # break\n","  \n","\n","#     # if tf.math.greater_equal(epoch,epoch_save): #if want to retrain might do it at every tenth model starting at 50..\n","#       #if want to retrain (e.g. further tha epoch 100 such as 200, than need to save all three models)\n","#     if epoch in epoch_save:\n","#       # Better save both as GAN is the orchestrated work of both the generator and discriminator together. --> seems like only gan?\n","#       save_model(file_path_to_save_model,'g_model',g_model,epoch)\n","#       # save_model(file_path_to_save_model,'d_model',d_model,epoch)\n","#       # save_model(file_path_to_save_model,'gan_model',gan_model,epoch)\n","\n","\n","#   #not sure if this would be too much for memory..\n","#   #save losses\n","#   fn_d1 = file_path_to_save_result + 'd1.txt'\n","#   np.savetxt(fn_d1, d1_hist) #these are nested lists!\n","#   fn_d2 = file_path_to_save_result + 'd2.txt'\n","#   np.savetxt(fn_d2, d2_hist)\n","#   fn_g = file_path_to_save_result + 'g.txt'\n","#   np.savetxt(fn_g, g_hist)\n","\n","\n","#   #save dice and iou as well\n","#   fn_iou = file_path_to_save_result+'iou_over_epochs.txt'\n","#   np.savetxt(fn_iou, iou_over_epochs)\n","\n","#   fn_iou = file_path_to_save_result+'iou_test_over_epochs.txt' \n","#   np.savetxt(fn_iou, iou_test_over_epochs)\n","\n","#   return d1_hist,d2_hist,g_hist,iou_over_epochs,iou_test_over_epochs\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WD4fqZro5PqL"},"source":["# for [x1,x2] in train_dataset.take(1):\n","\n","#     # select a batch of real samples\n","#     [source, target], y_real = generate_real_samples([x1,x2]) \n","#     # generate a batch of fake samples\n","#     gen_target, y_fake = generate_fake_samples(g_model, source)\n","#     print(src.shape,target.shape,gen_target.shape)  \n","\n","#     # save_images(src,target,gen_target,file_path_to_save_result,epoch)\n","#     for i in range(3):\n","#       src = source[i,:,:,0]\n","#       gen_tar = gen_target[i,:,:,0]\n","#       tar = target[i,:,:,0]\n","#       print(src.shape,gen_tar.shape,tar.shape)\n","#       images = [src,gen_tar,tar]\n","#       titles = [\"source\",\"generated target\",\"true target\"]\n","\n","#       f = plt.figure()\n","#       f.add_subplot(1,3, 1)\n","#       plt.title(titles[0])\n","#       plt.imshow(images[0])\n","#       plt.axis('off')\n","      \n","      \n","#       f.add_subplot(1,3, 2)\n","#       plt.title(titles[1])\n","#       plt.imshow(images[1])\n","#       plt.axis('off')\n","\n","#       f.add_subplot(1,3, 3)\n","#       plt.title(titles[2])\n","#       plt.imshow(images[2])\n","#       plt.axis('off')\n","\n","#       # filename1 = 'plot_s%i_%06d.png' % (i,step+1)\n","#       # plt.savefig(file_path_to_save + filename1)\n","#       # print(gen_tar) #nan nan ok.. well thats ok I guess.. bc its a real result..\n","#       plt.show()\n","#       plt.close()\n","\n","\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4pLNXPr-CQhy"},"source":["# def train(batch_train,batch_test,d_model=d_model, g_model=g_model, gan_model=gan_model,num_epochs = 100,epoch_stop =30,epoch_save=[49,99] ,file_path_to_save_model=path_to_save,file_path_to_save_result=path_results):\n","\n","#   \"\"\"\" train model\n","#   Here also loss is calculated\n","#   Also stops after dloss remains low and/or iou remains nan (aka 0/x ? what gives a nan value? )\n","#   Here only the iou and dice for the positive images is calculated\n","#   batch_train: the train dataset, tfrecord dataset which is batched\n","#   batch_test: the test dataset, tfrecord dataset which is batched, only ls images\n","#   No if condition on validation set since the validation is only ls images\n","#   \"\"\"\"\"\n","  \n","#   #dice and iou over epochs for train and test set.\n","#   iou_over_epochs,iou_test_over_epochs = list(), list()\n","#   d1_hist, d2_hist, g_hist = list(), list(), list()\n","\n","#   for epoch in tqdm(range(num_epochs)):\n","\n","#     #metric per image over all image in one epoch\n","#     iou_over_epoch,iou_test_over_epoch = list(), list()\n","#     d1_epoch, d2_epoch, g_epoch = list(),list(),list()\n","\n","#     for [x1,x2] in tqdm(batch_train):\n","\n","#       # select a batch of real samples\n","#       [src, target], y_real = generate_real_samples([x1,x2]) \n","#       # generate a batch of fake samples\n","#       gen_target, y_fake = generate_fake_samples(g_model, src)  \n","#       # update discriminator for real samples\n","#       d_loss1 = d_model.train_on_batch([src,target], y_real)\n","#        # update discriminator for generated samples\n","#       d_loss2 = d_model.train_on_batch([src, gen_target], y_fake)\n","#       # update the generator\n","#       g_loss, _, _ = gan_model.train_on_batch(src, [y_real, target])\n","\n","      \n","#       #get 0 band!\n","#       iou_over_batch = iou_coe(gen_target[:,:,:,0],target[:,:,:,0],axis=(1,2))\n","\n","#       #record loss history, to get a plot of converging (hopefully) dis & gen loss over epochs (only for train ds(?))\n","#       d1_epoch.append(d_loss1)\n","#       d2_epoch.append(d_loss2)\n","#       g_epoch.append(g_loss)\n","  \n","      \n","#       #save iou\n","#       iou_over_epoch.append(iou_over_batch)\n","\n","\n","\n","\n","\n","\n","# #retracing might be bc the batch_test has other size bc its smaller, so dif batch sizes..\n","#     for [x1,x2] in tqdm(batch_test):\n","#       target_pred = g_model.predict(x1)\n","#       iou_test = iou_coe(target_pred[:,:,:,0],x2[:,:,:,0],axis=(1,2))\n","#       #save iou\n","#       iou_test_over_epoch.append(iou_test)\n","\n","\n","#     #  #save the metric accross epochs.\n","#     iou_test_over_epochs.append(tf.reduce_mean(iou_test_over_epoch))\n","#     #save the metric accross epochs, for train\n","#     iou_over_epochs.append(tf.reduce_mean(iou_over_epoch))\n","         \n","\n","#     # out of batch loop, in epoch loop\n","#     # record history over epochs --> could either do mean of each epoch or just leave them for each batch.\n","#     d1_hist.append(d1_epoch)\n","#     d2_hist.append(d2_epoch)\n","#     g_hist.append(g_epoch)\n","\n","    \n","#     if tf.equal(epoch,epoch_stop): #this works!\n","#       print('d loss at epoch stop',d_loss1)\n","#       # print(d_loss1 == np.nan)\n","#       # print(d_loss1 == float('nan'))\n","\n","#       if tf.math.less(d_loss1,tf.constant(0.01)):\n","#         print('then should quit since d1 loss is close to zero:',d_loss1) #works\n","#         # break\n","#       elif np.isnan(d_loss1):\n","#         print(\"its nan\")\n","#         # break\n","  \n","\n","#     # if tf.math.greater_equal(epoch,epoch_save): #if want to retrain might do it at every tenth model starting at 50..\n","#       #if want to retrain (e.g. further tha epoch 100 such as 200, than need to save all three models)\n","#     if epoch in epoch_save:\n","#       # Better save both as GAN is the orchestrated work of both the generator and discriminator together. --> seems like only gan?\n","#       save_model(file_path_to_save_model,'g_model',g_model,epoch)\n","#       save_model(file_path_to_save_model,'d_model',d_model,epoch)\n","#       save_model(file_path_to_save_model,'gan_model',gan_model,epoch)\n","\n","      \n","\n","\n","#   #not sure if this would be too much for memory..\n","#   #save losses\n","#   fn_d1 = file_path_to_save_result + 'd1.txt'\n","#   np.savetxt(fn_d1, d1_hist) #these are nested lists!\n","#   fn_d2 = file_path_to_save_result + 'd2.txt'\n","#   np.savetxt(fn_d2, d2_hist)\n","#   fn_g = file_path_to_save_result + 'g.txt'\n","#   np.savetxt(fn_g, g_hist)\n","\n","\n","#   #save dice and iou as well\n","#   fn_iou = file_path_to_save_result+'iou_over_epochs.txt'\n","#   np.savetxt(fn_iou, iou_over_epochs)\n","\n","#   fn_iou = file_path_to_save_result+'iou_test_over_epochs.txt' \n","#   np.savetxt(fn_iou, iou_test_over_epochs)\n","\n","#   return d1_hist,d2_hist,g_hist,iou_over_epochs,iou_test_over_epochs\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z_5bVoJnsJx9"},"source":["With condition for mIoU; only ls targets."]},{"cell_type":"code","metadata":{"id":"w49mz5V_sHU8"},"source":[" def train(batch_train,batch_test,d_model=d_model, g_model=g_model, gan_model=gan_model,num_epochs = num_epochs,epoch_stop =30,epoch_save=[49,99] ,file_path_to_save_model=path_to_save,file_path_to_save_result=path_results):\n","\n","  \"\"\"\" train model\n","  Here also loss is calculated\n","  Also stops after dloss remains low and/or iou remains nan (aka 0/x ? what gives a nan value? )\n","  Here only the iou and dice for the positive images is calculated\n","  batch_train: the train dataset, tfrecord dataset which is batched\n","  batch_test: the test dataset, tfrecord dataset which is batched, only ls images\n","  No if condition on validation set since the validation is only ls images\n","  \"\"\"\"\"\n","  \n","  #dice and iou over epochs for train and test set.\n","  iou_over_epochs,iou_test_over_epochs = list(), list()\n","  d1_hist, d2_hist, g_hist = list(), list(), list()\n","\n","  for epoch in tqdm(range(num_epochs)):\n","\n","    #metric per image over all image in one epoch\n","    iou_over_epoch,iou_test_over_epoch = list(), list()\n","    d1_epoch, d2_epoch, g_epoch = list(),list(),list()\n","\n","    for [x1,x2] in tqdm(batch_train):\n","\n","      # select a batch of real samples\n","      [src, target], y_real = generate_real_samples([x1,x2]) \n","      # generate a batch of fake samples\n","      gen_target, y_fake = generate_fake_samples(g_model, src)  \n","      # update discriminator for real samples\n","      d_loss1 = d_model.train_on_batch([src,target], y_real)\n","       # update discriminator for generated samples\n","      d_loss2 = d_model.train_on_batch([src, gen_target], y_fake)\n","      # update the generator\n","      g_loss, _, _ = gan_model.train_on_batch(src, [y_real, target])\n","\n","      #get 0 band\n","      target_b = target[:,:,:,0]\n","      gen_target_b = gen_target[:,:,:,0]\n","\n","      iou_over_batch = []\n","      #with condition\n","      for i in range(target_b.shape[0]):\n","        condition = tf.math.reduce_any(target_b[i,:,:] == 1)\n","        if tf.equal(condtion,True):\n","          iou = iou_coe(gen_target_b[i,:,:],target_b[i,:,:],axis = (0,1))\n","  \n","          iou_over_batch.append(iou)\n","\n","      \n","      #save iou\n","      iou_over_epoch.append(iou_over_batch)\n","\n","\n","      #record loss history, to get a plot of converging (hopefully) dis & gen loss over epochs (only for train ds(?))\n","      d1_epoch.append(d_loss1)\n","      d2_epoch.append(d_loss2)\n","      g_epoch.append(g_loss)\n","  \n","\n","      if ((epoch+1) % 10 == 0):\n","        save_images(src,target,gen_target,file_path_to_save_result,epoch)\n","\n","\n","#retracing might be bc the batch_test has other size bc its smaller, so dif batch sizes..\n","    for [x1,x2] in tqdm(batch_test):\n","      target_pred = g_model.predict(x1)\n","      \n","      # 0 bands\n","      target_pred_b = target_pred[:,:,:,0]\n","      target_test_b = x2[:,:,:,0]\n","\n","      iou_test_over_batch = []\n","      #condition\n","      for i in range(target_pred_b.shape[0]):\n","        condition = tf.math.reduce_any(target_pred_b[i,:,:] == 1)\n","        if tf.equal(condition,True):\n","          iou_test = iou_coe(target_pred_b[i,:,:],target_test_b[i,:,:],axis=(0,1))\n","          #save iou\n","          iou_test_over_batch.append(iou_test)\n","          \n","          \n","        iou_test_over_epoch.append(iou_test)\n","\n","\n","    #  #save the metric accross epochs.\n","    iou_test_over_epochs.append(tf.reduce_mean(iou_test_over_epoch))\n","    #save the metric accross epochs, for train\n","    iou_over_epochs.append(tf.reduce_mean(iou_over_epoch))\n","         \n","\n","    # out of batch loop, in epoch loop\n","    # record history over epochs --> could either do mean of each epoch or just leave them for each batch.\n","    d1_hist.append(d1_epoch)\n","    d2_hist.append(d2_epoch)\n","    g_hist.append(g_epoch)\n","\n","    \n","    # if tf.equal(epoch,epoch_stop): #this works!\n","    #   print('d loss at epoch stop',d_loss1)\n","    #   # print(d_loss1 == np.nan)\n","    #   # print(d_loss1 == float('nan'))\n","\n","    #   if tf.math.less(d_loss1,tf.constant(0.01)):\n","    #     print('then should quit since d1 loss is close to zero:',d_loss1) #works\n","    #     # break\n","    #   elif np.isnan(d_loss1):\n","    #     print(\"its nan\")\n","    #     # break\n","  \n","\n","    # if tf.math.greater_equal(epoch,epoch_save): #if want to retrain might do it at every tenth model starting at 50..\n","      #if want to retrain (e.g. further tha epoch 100 such as 200, than need to save all three models)\n","    if epoch in epoch_save:\n","      # Better save both as GAN is the orchestrated work of both the generator and discriminator together. --> seems like only gan?\n","      save_model(file_path_to_save_model,'g_model',g_model,epoch)\n","      # save_model(file_path_to_save_model,'d_model',d_model,epoch)\n","      # save_model(file_path_to_save_model,'gan_model',gan_model,epoch)\n","\n","\n","  #not sure if this would be too much for memory..\n","  #save losses\n","  fn_d1 = file_path_to_save_result + 'd1.txt'\n","  np.savetxt(fn_d1, d1_hist) #these are nested lists!\n","  fn_d2 = file_path_to_save_result + 'd2.txt'\n","  np.savetxt(fn_d2, d2_hist)\n","  fn_g = file_path_to_save_result + 'g.txt'\n","  np.savetxt(fn_g, g_hist)\n","\n","\n","  #save dice and iou as well\n","  fn_iou = file_path_to_save_result+'iou_over_epochs.txt'\n","  np.savetxt(fn_iou, iou_over_epochs)\n","\n","  fn_iou = file_path_to_save_result+'iou_test_over_epochs.txt' \n","  np.savetxt(fn_iou, iou_test_over_epochs)\n","\n","  return d1_hist,d2_hist,g_hist,iou_over_epochs,iou_test_over_epochs\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KChx80x8BUA9"},"source":["6:52 h for bsize 32 with masked ls A ratio. --> how many img?? need to check!"]},{"cell_type":"markdown","metadata":{"id":"9BR16PU5J7AQ"},"source":["128 bsize is 1:43 on 81 percent\n","16 bsize just quits after 7 or 8  procent\n","64 also quits after 1h ong 30 percent"]},{"cell_type":"markdown","metadata":{"id":"5VH0IKjLR8qG"},"source":["With image plotting is 128 2:13 h"]},{"cell_type":"code","metadata":{"id":"wH_YQhlrvXQd"},"source":["#32 is 6:47 h with image plotting"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JlBbC0CX33hI"},"source":["#64 bsize 21 procent 53 min. Total 3:49 h\n","# 512 58:38 min\n","# 256 1:19"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"__MAaavM0T0O"},"source":["d1_hist,d2_hist,g_hist,iou_over_epochs,iou_test_over_epochs = train(train_dataset,val_dataset) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wUzJgNX1J_Uq"},"source":["print (n_batch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hziMkmBc1nYP"},"source":["#Check result"]},{"cell_type":"code","metadata":{"id":"i73MQJDe1vL3"},"source":["path_learning_curve = path_base + \"learning_curve/\"\n","path_loss_history = path_base + \"loss_history/\"\n","os.makedirs(path_learning_curve)\n","os.makedirs(path_loss_history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFTO2PkC2M-g"},"source":["version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4t2S69vx5bYR"},"source":["!ls -la {path_results}\n","path_results\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2KZGrIUp2Kef"},"source":["def load_metric_loss(name_txt_file,path_to_txt_file,fill_nan_value = -0.01):\n","#hopefully works as well for nested lists...\n","  metric_epochs = []\n","  with open (path_to_txt_file + name_txt_file, mode= 'r') as f:\n","    lines = f.readlines()\n","    # print(lines)\n","\n","    for i in range(len(lines)):\n","      metric_per_batch_per_epoch = lines[i].strip().split()\n","      # print(metric_per_batch_per_epoch) #so now need to split on ,\n","      for i in range(len(metric_per_batch_per_epoch)):\n","        metric_per_batch = metric_per_batch_per_epoch[i].split(',')\n","        # print(float(metric_per_batch[0]))\n","        metric_epochs.append(float(metric_per_batch[0]))\n","\n","    arr = np.array(metric_epochs)\n","    #fill nan value\n","    arr[np.isnan(arr)] = fill_nan_value  \n","\n","      # metric_epochs\n","\n","  return arr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w3Ba44_W10PO"},"source":["# create a line plot of loss for the gan and save to file\n","def plot_history(path_to_txt_file,name_result,path_to_save_result = path_loss_history):\n","  #why is this plot such bullshit?? Bc it doesnt represent the values truthfully!\n","\n","  d1 = load_metric_loss('/d1.txt',path_to_txt_file)\n","  d2 = load_metric_loss('/d2.txt',path_to_txt_file)\n","  g = load_metric_loss('/g.txt',path_to_txt_file)\n","\n","  # print(max(d1),max(d2),max(g))\n","\n","  plt.figure(figsize=(5,5))\n","  plt.plot(d1,label = 'd-real')\n","  plt.plot(d2, label='d-fake')\n","  plt.plot(g, label='gen')\n","\n","\n","  # plt.text(0,500,(f'max d1,d2,g are ' {max(d1_hist):.2f} 'respectively'))\n","  # plt.yticks([])\n","  # plt.yticks([0,1e-3,1e-2,1e-3,5e-1,1,100],labels = ['0','1e-3','1e-2','1e-3','5e-1','1','100'])\n","  plt.legend()\n","\t# # save plot to file\n","  plt.savefig(path_to_save_result + name_result + 'plot_line_plot_loss.png',dpi=300, bbox_inches='tight')\n","  plt.show()\n","  plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7T_Rr-R8QOZh"},"source":["def load_metric_iou(name_txt_file,path_to_txt_file):\n","\n","  metric_epochs = []\n","  with open (path_to_txt_file + name_txt_file, mode= 'r') as f:\n","    lines = f.readlines()\n","    for i in range(len(lines)):\n","      metric_per_batch_per_epoch = lines[i].strip().split()\n","      metric_mean_per_epo = np.mean(np.array(metric_per_batch_per_epoch,dtype = np.float32))\n","      metric_epochs.append(metric_mean_per_epo)\n","  return metric_epochs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PL_cTXSo6yN2"},"source":["def learning_curve_v1(iou,iou_val,path_to_txt_file,name_result,name_fig,path_to_save_result=path_learning_curve):\n","  num_epochs = len(iou)\n","  epochs_range = range(num_epochs)\n","  \n","  plt.figure(figsize=(5, 5), dpi=200)\n","  plt.plot(epochs_range, iou, label='Training')\n","  plt.plot(epochs_range, iou_val, label='Validation')\n","  plt.legend(loc='lower right')\n","  plt.title('Training and Validation IoU')\n","  plt.xlabel('Epoch')\n","  plt.ylabel('IoU')\n","  plt.ylim(0, 1)\n","\n","\n","  plt.savefig(path_to_save_result + name_result + name_fig + '.png',dpi=300, bbox_inches='tight')\n","  plt.tight_layout()\n","  plt.show()\n","  plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIxoFU4z17rZ"},"source":["def run_curves(file):\n","\n","\n","  result_part = file.split('/attempt_')[-1].split(\"/\")[0]\n","\n","  # print(path_learning_curve + result_part)\n","  \n","\n","  iou_epochs = load_metric_iou(\"iou_over_epochs.txt\",path_to_txt_file=file)\n","  iou_test_epochs = load_metric_iou(\"iou_test_over_epochs.txt\",path_to_txt_file=file)\n","  learning_curve_v1(iou_epochs,iou_test_epochs,path_to_txt_file=file,name_result=result_part,name_fig='_learning_curve_iou')\n","  # print(path_loss_history+result_part)\n","  plot_history(path_to_txt_file = file,name_result = result_part) #why not doing this    \n","\n","\n","# def run_curves(f):\n","#   \"f are the dirs in the folder of each run which lead to the results txt files of each run \"\n","#   for i in range(len(f)):\n","#     file = f[i]\n","\n","#     result_part = file.split('/attempt_')[-1]\n","\n","#     # print(path_learning_curve + result_part)\n","    \n","\n","#     iou_epochs = load_metric_iou(\"iou_over_epochs.txt\",path_to_txt_file=file)\n","#     iou_test_epochs = load_metric_iou(\"iou_test_over_epochs.txt\",path_to_txt_file=file)\n","#     learning_curve_v1(iou_epochs,iou_test_epochs,path_to_txt_file=file,name_result=result_part,name_fig='_learning_curve_iou')\n","#     # print(path_loss_history+result_part)\n","#     plot_history(path_to_txt_file = file,name_result = result_part) #why not doing this\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TYBXdrNL2ZMp"},"source":["run_curves(path_results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LFiczKYQKiej"},"source":["# Retrain loaded model"]},{"cell_type":"code","metadata":{"id":"eQKBy6LSKlao"},"source":["path_models = '/content/drive/MyDrive/Thesis/dif_incl_mask/models/'\n","!ls -la {path_models}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzCZgFgvQMlf"},"source":["path_to_save = path_models + \"attempt_1_2709_bcedice_bsize_128/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M9bbWpUHKmqw"},"source":["## load model"]},{"cell_type":"code","metadata":{"id":"tSAVljfNKnub"},"source":["# example of loading a pix2pix model and using it for image to image translation\n","from keras.models import load_model\n","from numpy import load\n","from numpy import vstack\n","from numpy.random import randint\n","\n","!ls -la {path_to_save}\n","\n","fn_models = [str(f) for f in pathlib.Path(path_to_save).glob('*.h5')]\n","fn_models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"anl5jS_BKqbw"},"source":["# fn_d_model = path_to_save + \"d_model__100.h5\"\n","# fn_g_model = path_to_save + \"g_model__100.h5\"\n","fn_gan_model = fn_models[-1]\n","fn_d_model = fn_models[-2]\n","fn_g_model = fn_models[-3]\n","\n","print(\"the models are\",fn_gan_model,fn_d_model,fn_g_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A95eouVrKu1P"},"source":["\n","\n","epoch_loaded_model = int(fn_gan_model.split(\"__\",1)[-1].split(\".h5\")[0]) #but then al should have names with __\n","epoch_loaded_model\n","\n","# But then should have the gan, gen and dis...\n","\n","with tpu_strategy.scope():\n","    # load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n","    # d_model = tf.keras.models.load_model(fn_d_model)\n","    # g_model = tf.keras.models.load_model(fn_g_model)\n","    # gan_model = tf.keras.models.load_model(fn_gan_model)#,custom_objects = {'binary_focal_loss_plus_dice_loss':binary_focal_dice_loss}, options=load_locally) # loading in Tensorflow's \"SavedModel\" format\n","\n","#with particular loss aka custom objects\n","    d_model = tf.keras.models.load_model(fn_d_model,custom_objects= {'binary_crossentropy_plus_dice_loss':bce_dice_loss})\n","    g_model = tf.keras.models.load_model(fn_g_model,custom_objects= {'binary_crossentropy_plus_dice_loss':bce_dice_loss})\n","    gan_model = tf.keras.models.load_model(fn_gan_model,custom_objects= {'binary_crossentropy_plus_dice_loss':bce_dice_loss})\n","\n","d_model.summary()\n","\n","g_model.summary()\n","\n","gan_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3evtGRAQK8Vj"},"source":["## Run train on reloaded model\n","\n","new path to save results and model to..\n","add real epoch nr for use for file name f saved model. ad possibly in results name\n"]},{"cell_type":"code","metadata":{"id":"dYk7IODWR2wo"},"source":["# FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Thesis/dif_incl_mask/results/attempt_2_2809_bcedice_bsize_128/rerun1/d1.txt'\n","\n","#Need to save these paths!"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Em6DBGCK5Te"},"source":["\n","def train(batch_train,batch_test,d_model=d_model, g_model=g_model, gan_model=gan_model,num_epochs = 50,epoch_stop =30,epoch_begin_rerun = epoch_loaded_model,epoch_save=[49,59,69,79,89,99] ,file_path_to_save_model=path_to_save,file_path_to_save_result=path_results):\n","\n","  \"\"\"\" train model\n","  Here also loss is calculated\n","  Also stops after dloss remains low and/or iou remains nan (aka 0/x ? what gives a nan value? )\n","  Here only the iou and dice for the positive images is calculated\n","  batch_train: the train dataset, tfrecord dataset which is batched\n","  batch_test: the test dataset, tfrecord dataset which is batched, only ls images\n","  No if condition on validation set since the validation is only ls images\n","  \"\"\"\"\"\n","\n","  file_path_to_save_model = file_path_to_save_model + \"rerun1/\"\n","  file_path_to_save_result = file_path_to_save_result + \"rerun1/\"\n","  # os.makedirs(file_path_to_save_model)\n","  # os.makedirs(file_path_to_save_result)\n","  \n","  #dice and iou over epochs for train and test set.\n","  iou_over_epochs,iou_test_over_epochs = list(), list()\n","  d1_hist, d2_hist, g_hist = list(), list(), list()\n","\n","  for epoch in tqdm(range(num_epochs)):\n","\n","    #metric per image over all image in one epoch\n","    iou_over_epoch,iou_test_over_epoch = list(), list()\n","    d1_epoch, d2_epoch, g_epoch = list(),list(),list()\n","\n","    for [x1,x2] in tqdm(batch_train):\n","\n","      # select a batch of real samples\n","      [src, target], y_real = generate_real_samples([x1,x2]) \n","      # generate a batch of fake samples\n","      gen_target, y_fake = generate_fake_samples(g_model, src)  \n","      # update discriminator for real samples\n","      d_loss1 = d_model.train_on_batch([src,target], y_real)\n","       # update discriminator for generated samples\n","      d_loss2 = d_model.train_on_batch([src, gen_target], y_fake)\n","      # update the generator\n","      g_loss, _, _ = gan_model.train_on_batch(src, [y_real, target])\n","\n","\n","      #record loss history, to get a plot of converging (hopefully) dis & gen loss over epochs (only for train ds(?))\n","      d1_epoch.append(d_loss1)\n","      d2_epoch.append(d_loss2)\n","      g_epoch.append(g_loss)\n","    \n","\n","      iou_over_batch = iou_coe(gen_target[:,:,:,0],target[:,:,:,0],axis=(1,2))\n","    \n","      #save iou\n","      iou_over_epoch.append(iou_over_batch)\n","  \n","#retracing might be bc the batch_test has other size bc its smaller, so dif batch sizes..\n","    for [x1,x2] in tqdm(batch_test):\n","      target_pred = g_model.predict(x1)\n","\n","      iou_over_batch = iou_coe(target_pred[:,:,:,0],x2[:,:,:,0],axis=(1,2))\n","       \n","      #save iou\n","      iou_test_over_epoch.append(iou_over_batch)\n","\n","\n","    #  #save the metric accross epochs.\n","    iou_test_over_epochs.append(tf.reduce_mean(iou_test_over_epoch))\n","    iou_over_epochs.append(tf.reduce_mean(iou_over_epoch))\n","    \n","         \n","\n","    # out of batch loop, in epoch loop\n","    # record history over epochs --> could either do mean of each epoch or just leave them for each batch.\n","    d1_hist.append(d1_epoch)\n","    d2_hist.append(d2_epoch)\n","    g_hist.append(g_epoch)\n","\n","  \n","    if tf.equal(epoch,epoch_stop): #this works!\n","      print('d loss at epoch stop',d_loss1)\n","      # print(d_loss1 == np.nan)\n","      # print(d_loss1 == float('nan'))\n","\n","      if tf.math.less(d_loss1,tf.constant(0.01)):\n","        print('then should quit since d1 loss is close to zero:',d_loss1) #works\n","        # break\n","      elif np.isnan(d_loss1):\n","        print(\"its nan\")\n","        # break\n","  \n","\n","    # if tf.math.greater_equal(epoch,epoch_save): #if want to retrain might do it at every tenth model starting at 50..\n","      #if want to retrain (e.g. further tha epoch 100 such as 200, than need to save all three models)\n","    if epoch in epoch_save:\n","      epoch_rerun = epoch + epoch_begin_rerun \n","      # Better save both as GAN is the orchestrated work of both the generator and discriminator together. --> seems like only gan?\n","      save_model(file_path_to_save_model,\"g_model\",g_model,epoch_rerun)\n","      save_model(file_path_to_save_model,\"d_model\",d_model,epoch_rerun)\n","      save_model(file_path_to_save_model,\"gan_model\",gan_model,epoch_rerun)\n","\n","\n","\n","\n","  #not sure if this would be too much for memory..\n","  #save losses\n","  fn_d1 = file_path_to_save_result + 'd1.txt'\n","  np.savetxt(fn_d1, d1_hist) #these are nested lists!\n","  fn_d2 = file_path_to_save_result + 'd2.txt'\n","  np.savetxt(fn_d2, d2_hist)\n","  fn_g = file_path_to_save_result + 'g.txt'\n","  np.savetxt(fn_g, g_hist)\n","\n","\n","  #save  iou as well\n","  fn_iou = file_path_to_save_result+'iou_over_epochs.txt'\n","  np.savetxt(fn_iou, iou_over_epochs)\n","\n","  fn_iou = file_path_to_save_result+'iou_test_over_epochs.txt' \n","  np.savetxt(fn_iou, iou_test_over_epochs)\n","\n","  #to be sure return these bitches\n","  return d1_hist,d2_hist,g_hist,iou_over_epochs, iou_test_over_epochs\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0qmsPa6K-8G"},"source":["\n","d1_hist,d2_hist,g_hist,iou_over_epochs, iou_test_over_epochs = train(train_dataset,val_dataset) "],"execution_count":null,"outputs":[]}]}