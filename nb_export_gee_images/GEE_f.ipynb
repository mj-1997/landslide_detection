{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GEE_f.ipynb","provenance":[],"collapsed_sections":["YUjt6t_1rj7y"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vqQYpee219n-"},"source":["#Notebook"]},{"cell_type":"markdown","metadata":{"id":"y4PdngLr2Cwk"},"source":["This notebook comprises the epxorting of google earth engine images to tiff files/images which are ready to be processed to tfrecords as training images\n","\n","Here images are filtered by\n"," -  time\n"," - region\n"," - fit into tiles\n"," - exported/dowloaded to local google drive as tiff images"]},{"cell_type":"markdown","metadata":{"id":"YUjt6t_1rj7y"},"source":["# Install libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DpEMHgYAuG9f","executionInfo":{"status":"ok","timestamp":1633442430523,"user_tz":-120,"elapsed":22786,"user":{"displayName":"marja machielse","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00933235277742921282"}},"outputId":"606e6bcb-ee8e-4a8f-a799-7bae3961359f"},"source":["\n","!pip -q install -U geemap\n","!pip -q install geopandas shapely\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 476 kB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n","\u001b[K     |████████████████████████████████| 76 kB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 219 kB 46.9 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 51.1 MB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 23.7 MB/s \n","\u001b[K     |████████████████████████████████| 3.3 MB 18.9 MB/s \n","\u001b[K     |████████████████████████████████| 130 kB 69.4 MB/s \n","\u001b[K     |████████████████████████████████| 98 kB 7.0 MB/s \n","\u001b[K     |████████████████████████████████| 93 kB 1.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 52.1 MB/s \n","\u001b[K     |████████████████████████████████| 97 kB 6.6 MB/s \n","\u001b[K     |████████████████████████████████| 70 kB 7.3 MB/s \n","\u001b[K     |████████████████████████████████| 393 kB 62.7 MB/s \n","\u001b[K     |████████████████████████████████| 553 kB 61.2 MB/s \n","\u001b[K     |████████████████████████████████| 112 kB 49.8 MB/s \n","\u001b[K     |████████████████████████████████| 428 kB 49.2 MB/s \n","\u001b[K     |████████████████████████████████| 78 kB 5.9 MB/s \n","\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n","\u001b[?25h  Building wheel for pyshp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ipynb-py-convert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pycrs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.12.1 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 1.0 MB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 6.3 MB 48.0 MB/s \n","\u001b[K     |████████████████████████████████| 15.4 MB 24 kB/s \n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"lWRLG_Y_9NrW"},"source":["import geopandas as gpd\n","import glob\n","import pandas as pd\n","import os\n","\n","# import geetools\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AkI2qkKNpdxI"},"source":["### Rasterio"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6qPIZtPMoiH6","executionInfo":{"status":"ok","timestamp":1633442439030,"user_tz":-120,"elapsed":6579,"user":{"displayName":"marja machielse","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00933235277742921282"}},"outputId":"6809651b-507b-4a0e-ee5a-8612c194d6c3"},"source":["!pip install -q rasterio"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 19.3 MB 56.3 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"AUVupNJVolPY"},"source":["import rasterio"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"opmHxXeWra6v"},"source":["#Authenticate\n"]},{"cell_type":"markdown","metadata":{"id":"ggVjuAMtuP8i"},"source":["## Authenticate to GEE\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZTHvGvwuQNq","executionInfo":{"status":"ok","timestamp":1633442488697,"user_tz":-120,"elapsed":20813,"user":{"displayName":"marja machielse","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00933235277742921282"}},"outputId":"3ca85fcb-0184-49a1-b1df-a089eddca39c"},"source":["\n","import ee\n","import geemap.eefolium as geemap\n","ee.Authenticate()\n","ee.Initialize()\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n","\n","    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=9r3YXuF4QfZY4aP4d4jkMktrpW_z5_bw7WBqy1ZsW40&code_challenge_method=S256\n","\n","The authorization workflow will generate a code, which you should paste in the box below. \n","Enter verification code: 4/1AX4XfWgoDrTyjsz6XKkqzpfJNlhSi7I8na3njQbLfSslSfShuzX02HVrtaE\n","\n","Successfully saved authorization token.\n"]}]},{"cell_type":"markdown","metadata":{"id":"gtTbqsC6JJc-"},"source":["## Authenticate to Drive\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5C_cvzgE6po","executionInfo":{"status":"ok","timestamp":1633442505198,"user_tz":-120,"elapsed":16517,"user":{"displayName":"marja machielse","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00933235277742921282"}},"outputId":"82de48a3-6dc6-418f-ee95-5e1018500a95"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"owo6Wu23oj_s"},"source":["pathExp = \"dB2709/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bCiDGKX0rS_T"},"source":["# Import data"]},{"cell_type":"markdown","metadata":{"id":"aLdcI2ba_389"},"source":["##Load assets: y data and tiles\n","The y data are the masked target images. The NonLS images are black, the LS images are black and white. The landslide polygons are colored white.\n","The tiles are geometries, tiles produced by rasterization, corresponding to approx. 2 by 2 km^2. The satellite images will be exported with the size of these tiles. \n"]},{"cell_type":"code","metadata":{"id":"eCbtdaUQ_7s-"},"source":["tilesHiro = ee.FeatureCollection(\"users/marjamachielsegg/HiroTiles\")\n","tilesHokkaido = ee.FeatureCollection(\"users/marjamachielsegg/HokTiles\")\n","tilesHu = ee.FeatureCollection(\"users/marjamachielsegg/HuTiles\")\n","tilesLombok = ee.FeatureCollection(\"users/marjamachielsegg/LombokTiles\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"soaSM1uDCAwR"},"source":["HiroY = ee.Image(\"users/marjamachielsegg/HiroY10\")\n","HuY = ee.Image(\"users/marjamachielsegg/HuY10m\")\n","HokY = ee.Image(\"users/marjamachielsegg/HokY10m_2\")\n","LombokY = ee.Image(\"users/marjamachielsegg/LombokY10m\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iQNpmzNUJlyp"},"source":["HiroYNonLS = ee.Image(\"users/marjamachielsegg/HiroYNonLS20m\")\n","HuYNonLS = ee.Image(\"users/marjamachielsegg/HuYNonLS20m_2\")\n","HokYNonLS = ee.Image(\"users/marjamachielsegg/HokYNonLS20m\")\n","LombokYNonLS = ee.Image(\"users/marjamachielsegg/LombokYNonLS20m\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nf2ZVo2LJuTM"},"source":["## Load ImageCollections from Google Drive and make LS inventory dictionary"]},{"cell_type":"code","metadata":{"id":"8FMKaCxC9gwd"},"source":["# L8TOA = ee.ImageCollection(\"LANDSAT/LC08/C01/T1_RT_TOA\")\n","#use dB here!\n","S1dB = ee.ImageCollection(\"COPERNICUS/S1_GRD\")\n","# S2 = ee.ImageCollection(\"COPERNICUS/S2\")\n","\n","#Might need to redo these geometries, to make them slightly bigger so that they include all polygons\n","Hiroshima = ee.Geometry.Polygon(\n","    [[[132.6862647368235, 34.15717773816654],\n","      [132.9389502836985, 34.275280475796855],\n","      [133.230087979011, 34.32973356797482],\n","      [133.559677822761, 34.479297379909966],\n","      [133.5761573149485, 34.61503224648198],\n","      [133.186142666511, 34.700883075516785],\n","      [133.021347744636, 34.60599014490323],\n","      [132.3676612211985, 34.51098864780678],\n","      [132.329209072761, 34.261661687255],\n","      [132.4335791899485, 34.15717773816654]]])\n","Hokkaido = ee.Geometry.Polygon(\n","    [[[141.88807524167268, 42.94444603183977],\n","      [141.78919828854768, 42.85189180928013],\n","      [141.80567778073518, 42.69059710692225],\n","      [141.95948637448518, 42.56530485503135],\n","      [142.15527119607927, 42.58957464929461],\n","      [142.16625752420427, 42.78742433456754],\n","      [142.08935322732927, 42.867998174992415]]])\n","China = ee.Geometry.Polygon(\n","    [[[95.0742421678175, 29.999903555631697],\n","      [94.86275535141125, 29.74029674997442],\n","      [95.18959861313, 29.62576058848347],\n","      [95.38784688756272, 29.828495879457826]]])\n","Lombok = ee.Geometry.Polygon(\n","    [[[116.30332651211572, -8.568466262153649],\n","      [116.62604990078759, -8.462530449782491],\n","      [116.66724863125634, -8.309007726713741],\n","      [116.48322763516259, -8.242417181981912],\n","      [116.23328867031884, -8.270957365010824],\n","      [116.04789438320947, -8.4543803292391],\n","      [116.10831918789697, -8.527725191173909]]])\n","# visParams = {\"bands\":[\"swir\",\"nir\",\"red\"],\"min\":0.05,\"max\":0.4}\n","L8 = ee.ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")\n","# S1Float = ee.ImageCollection(\"COPERNICUS/S1_GRD_FLOAT\")\n","# ColorScale = {\"min\":-3,\"max\":3,\"palette\":[\"ffffff\",\"ffffff\",\"ff0000\"]}\n","\n","#Take slope instead of elevation\n","srtm = ee.Image(\"USGS/SRTMGL1_003\")\n","slope = ee.Terrain.slope(srtm.select(\"elevation\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TVhB9j0tN_aL"},"source":["dbLS = [\n","  {\n","    'name': \"Hiroshima\",\n","    # 'ft': eeHiroshima,\n","    'geom': Hiroshima,\n","    'tiles': tilesHiro,\n","    'eventDate' : \"2018-07-07\", #by Adriano; most happend evening 6, morning 7\n","    't1': \"2018-06-28\",\n","    't2': \"2018-07-09\",\n","    'amountOfTiles':1088,\n","    'YLS':HiroY,\n","    'YNonLS':HiroYNonLS\n","  },\n","  {\n","    'name': \"Hu\",\n","    # 'ft': eeHu,\n","    'geom': China,\n","    'tiles': tilesHu,\n","    'eventDate' : \"2017-11-17\", #or 18..\n","    't1': \"2017-11-16\",\n","    't2':\"2017-11-19\",\n","    'amountOfTiles':292,\n","    'YLS':HuY,\n","    'YNonLS':HuYNonLS\n","  },\n","  {\n","    'name': \"FerrarioMerge\", \n","    # 'ft': eeLombokMerge, \n","    'tiles': tilesLombok,\n","    'geom': Lombok,\n","    'eventDate' : \"2018-07-29\", #for consec used FerB, with eventDate 2018-08-05..\n","    't1':\"2018-07-28\",\n","    't2': \"2018-08-20\",\n","    'amountOfTiles':331,\n","    'YLS':LombokY,\n","    'YNonLS':LombokYNonLS\n","  },\n","  {\n","    'name': \"HokkaidoMerge\",\n","    # 'ft':eeHokkaidoMerge, \n","    'geom': Hokkaido,\n","    'tiles': tilesHokkaido,\n","    'eventDate' : \"2018-10-06\", #why not 2018-10-06\n","    't1': \"2018-10-06\",\n","    't2':\"2018-10-07\",#last aftershock 21 feb 2019?\n","    'amountOfTiles':336,\n","    'YLS':HokY,\n","    'YNonLS':HokYNonLS\n","  }\n","  ]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eSTaxJZaPzW7"},"source":["## Export DEM data"]},{"cell_type":"code","metadata":{"id":"tSb9_WpeQBvF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ocWQ8MevQL8s","executionInfo":{"status":"ok","timestamp":1635595209621,"user_tz":-120,"elapsed":15,"user":{"displayName":"marja machielse","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00933235277742921282"}}},"source":["def exportOneImage_dem(index,image,image_projection, tile_nr, folder_name):\n","  \"\"\"\n","  This function exports one image from the Digital Elevation Model (DEM) satellite imagery.\n","  This function is called by the function export_dem, which calls all the images for one region/database.\n","  The input variable 'index' refers to the index of the landslide database, which region/database of the four databases is selected.\n","  These four databased are summed in the dbLS. \n","  [0] refers to Hiroshima, Japan\n","  [1] refers to Tsangpo Gorge, Chinna\n","  [2] refers to Lombok, Indonesia\n","  [3] refers to Hokkaido, Japan\n","\n","  The input variable 'image' refers to the image which is to be exported\n","\n","  The input variable 'image_projection' refers to the projection of the image which is to be exported\n","\n","  The 'region' variable depicts the region which the image represents, here this is bound to a certain tile. \n","  Which tile this is, from the amount of tiles available for each region, is defined by the input variable 'tile_nr'\n","\n","  The input varialbe 'folder_name' refers to the name of the folder in the Drive to which the exported images\n","  are to be saved. This folder is made by the function but can also be made beforehand.\n","\n","  The image is of dimension 256 by 256 pixels, this can be changed at variable 'dimensions'\n","  The name of the image is defined by 'name_image', currently it is chosen to change that automatically\n","  wrt the tile number.\n","  \"\"\"\n","  tiles = dbLS[index][\"tiles\"]\n","  tiles_amount = tiles.size().getInfo()\n","  tiles_list = tiles.toList(tiles_amount)\n","  geom_tile = ee.Feature(tiles_list.get(tile_nr)).geometry().bounds(1,image_projection)\n","  name_image = \"ImageDEM_%s\" % (tile_nr) #ImageIMAGENUMBERFROMCOLL_TILENUMBER'\n","  ee.batch.Export.image.toDrive(\n","  image = image,\n","  dimensions = \"256x256\",          \n","  region = geom_tile,\n","  description = name_image,\n","  fileNamePrefix = name_image, #necessary next to descirptioN?\n","  folder = folder_name).start()"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMcYb9_rQHT2"},"source":["def export_dem(index,folder_name_dem):\n","  \"\"\"\n","  This function exports all images of the Digital Elevation Model (DEM) satellite imagery for a certain landslide database/area. \n","  The input variable 'index' refers to the index of the landslide database, which region/database of the four databases is selected.\n","  These four databased are summed in the dbLS. \n","  [0] refers to Hiroshima, Japan\n","  [1] refers to Tsangpo Gorge, Chinna\n","  [2] refers to Lombok, Indonesia\n","  [3] refers to Hokkaido, Japan\n","\n","  The input varialbe 'folder_name_dem' refers to the name of the folder in the Drive to which the exported images\n","  are to be saved. This folder is made by the function but can also be made beforehand.\n","  \"\"\"\n","  # // LOAD Shuttle Radar Topography Mission (SRTM) Digital Elevation Model (DEM)\n","  dataset = ee.Image('USGS/SRTMGL1_003')\n","  elevation = dataset.select('elevation') \n","  slope = ee.Terrain.slope(elevation);\n","  #get tiles\n","  tiles = dbLS[index][\"tiles\"]\n","  tiles_amount = tiles.size().getInfo()\n","  \n","  image_projection = slope.projection()\n","  for i in range(tiles_amount):\n","    tile_nr = i + 1\n","    exportOneImage_dem(index,slope,image_projection,tile_nr,folder_name_dem)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5iEEJ_de3ov9"},"source":["## Export Y data"]},{"cell_type":"code","metadata":{"id":"pxnfF80bzCsH"},"source":["S1 = S1dB"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Zcm064oHv4P"},"source":["def getImageProjection(index):\n","  t1 = dbLS[index][\"t1\"]\n","  t2 = dbLS[index][\"t2\"]\n","  images = S1.filterDate(t1,t2).filterBounds(dbLS[index][\"geom\"]).filter(ee.Filter.eq('resolution_meters', 10))\n","  imagesVH =  images.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')).filter(ee.Filter.eq('instrumentMode', 'IW')).select('VH')\n","  imagesdes = imagesVH.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')).sort('system:time_start')\n","  image = imagesdes.first()\n","  imageProjection = image.select(0).projection()\n","  return imageProjection"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZ-sos3Q3owA"},"source":["def exportImageYLS(folderNameLS,index):\n","  \"\"\"\n","  This function exports all images of the target images which contain landslide polygons for a certain landslide database/area. \n","  The input variable 'index' refers to the index of the landslide database, which region/database of the four databases is selected.\n","  These four databased are summed in the dbLS. \n","  [0] refers to Hiroshima, Japan\n","  [1] refers to Tsangpo Gorge, Chinna\n","  [2] refers to Lombok, Indonesia\n","  [3] refers to Hokkaido, Japan\n","\n","  The input varialbe 'folder_nameLS' refers to the name of the folder in the Drive to which the exported images\n","  are to be saved. This folder is made by the function but can also be made beforehand.\n","\n","\n","  The image is of dimension 256 by 256 pixels, this can be changed at variable 'dimensions'\n","  The name of the image is defined by 'name_image', currently it is chosen to change that automatically\n","  wrt the tile number.\n","  \"\"\"\n","  imageYLS = dbLS[index][\"YLS\"]\n","  tilesToUse = dbLS[index][\"tiles\"]\n","  amountOfTiles = tilesToUse.size().getInfo()\n","  print(amountOfTiles)\n","  tilesList = tilesToUse.toList(amountOfTiles)\n","\n","\n","  imageProjection = getImageProjection(index) #sar band, proj of des\n","  for i in range(amountOfTiles): \n","    geomTile = ee.Feature(tilesList.get(i)).geometry().bounds(1,imageProjection)\n","    nameImageLS = \"ImageLS_%s\" % (i) #Image_TILENUMBER\n","    ee.batch.Export.image.toDrive(\n","    image = imageYLS,\n","    dimensions = \"256x256\",           \n","    region = geomTile,\n","    description = nameImageLS,\n","    fileNamePrefix = nameImageLS,\n","    folder = folderNameLS).start()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S7fvokGKJ1cq"},"source":["#Functions"]},{"cell_type":"markdown","metadata":{"id":"76M8jzeMVFr1"},"source":["### Functions to get images with loaded tiles"]},{"cell_type":"code","metadata":{"id":"v6yyZ2RHQg9F"},"source":["\n","# def getImagesVH(ic):\n","#   imgVH = ic.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')).filter(ee.Filter.eq('instrumentMode', 'IW')).select('VH')\n","\n","#   #do some kind of DEM filtering here? or do DEM as extra band such that cGAN has two bands..\n","#   return imgVH"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYZxq8a3Te-7"},"source":["## Here the slope and curvature mask is made, for details see Handwerger, A., Jones, S., Huang, M.-H., Amatya, P., Kerner, H., and\n","# Kirschbaum, D. (2020). Rapid landslide identification using synthetic aperture\n","# radar amplitude change detection on the Google Earth Engine. Nat. Hazards\n","# Earth Syst. Sci.\n","\n","slope_threshold = .5#; // unit: degree\n","curv_threshold = -0.005#; // unit: m/m^2\n","\n","# // LOAD Shuttle Radar Topography Mission (SRTM) Digital Elevation Model (DEM)\n","dataset = ee.Image('USGS/SRTMGL1_003')\n","elevation = dataset.select('elevation') \n","slope = ee.Terrain.slope(elevation) #//slope in degrees\n","mask_slope = slope.gte(slope_threshold) #// slope mask with values 0 or 1\n","slope_mask = slope.updateMask(mask_slope)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4XjfdpYqrwW"},"source":["\n","# // Calculate curvature\n","# // Define a Gaussian kernel for smoothing. This step helps reduce noise in the curvature maps\n","# smooth_curv = ee.Kernel.gaussian({radius = 120,sigma = 60,units = 'meters',normalize = true})\n","\n","smooth_curv = ee.Kernel.gaussian(radius = 120,sigma = 60,units = 'meters',normalize = True)\n","xyDemGrad = elevation.convolve(smooth_curv).gradient()\n","xGradient = xyDemGrad.select('x').gradient()\n","yGradient = xyDemGrad.select('y').gradient()\n","curvature = xGradient.select('x').add(yGradient.select('y'))\n","mask_curvature = curvature.gte(curv_threshold)\n","curvature_mask = slope.updateMask(mask_curvature)\n","\n","# // Define a Gaussian kernel to reduce noise in S1 scenes\n","smooth_S1 = ee.Kernel.gaussian(radius = 50,sigma = 20, units = 'meters',normalize = True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sN5mc-XxsEVg"},"source":["def neg30(image):\n","  \"\"\"\"\n","  This function removes all pixels which have a value which is smaller than -30 dB from an image,\n","  defined by the input variable \"image\", whic is recommended for the Copernicus Sentinel-1 imagery from Google Earth Engine.\n","  Returned is the image, with said pixels removed\n","  \"\"\"\"\n","  return image.updateMask(image.gt(-30.0))\n","\n","\n","def getImagesVH(ic):\n","  \"\"\"\"\n","  This function filter the input variable \"ic\", which is an image collection of Copernicus Sentinel-1 imagery from Google Earth Engine,\n","  on VH polarization, IW mode and implements the neg30 function. Returned is an image collection, which is filtered on the aforementioned.\n","  \"\"\"\"\n","  imgVH = ic.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')).filter(ee.Filter.eq('instrumentMode', 'IW')).select('VH')\n","  imgVH_no_neg30 = imgVH.map(neg30) #Then these pixels become 0\n","  return imgVH_no_neg30\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M-3HdTaFTwBY"},"source":["def getDes(ic):\n","  \"\"\"\"\n","  This function returns the input variable \"ic\", which is an image collection of Copernicus Sentinel-1 imagery from Google Earth Engine,\n","  with only images of orbit with descending direction.\n","  \"\"\"\"\n","  des = ic.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')).sort('system:time_start')\n","  return des\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LnshHyhuQAjG"},"source":["def getAsc(ic):\n","  \"\"\"\"\n","  This function returns the input variable \"ic\", which is an image collection of Copernicus Sentinel-1 imagery from Google Earth Engine,\n","  with only images of orbit with ascending direction.\n","  \"\"\"\"\n","  asc = ic.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')).sort('system:time_start')\n","  return asc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RaULZgOYTHd4"},"source":["def getImagesPre(S,index, dateRange,stringMWY):\n","  \"\"\"\"\n","  This function returns the pre-event images, which is to say images which have happened before the landslide event happens. \n","  The input variable \"S\" refers to the image collection of Copernicus Sentinel-1 imagery from Google Earth Engine, the version which is in decibel.\n","  The input variable 'index' refers to the index of the landslide database, which region/database of the four databases is selected.\n","  These four databased are summed in the dbLS. \n","  [0] refers to Hiroshima, Japan\n","  [1] refers to Tsangpo Gorge, Chinna\n","  [2] refers to Lombok, Indonesia\n","  [3] refers to Hokkaido, Japan\n","\n","  The input variable 'dateRange' refers to the amount of time, and is given in integers.\n","  The input variable 'stringMWY' refers to the unit of time, is given in a string, and can be either :\n","  'day','month','year'.\n","  Together they make up the amount of time during which the images can be selected before the event date, e.g. \n","  'dateRange' = 1 , stringMWY = 'month' gives images during the timespan of 1 month before the event date.\n","  The event date can be found in the dbLS. The pre-event date and post-event date can differ per event, this is explained in the thesis. \n","\n","  Images of orbit with ascending and descending direction are returned separetely.\n","  \"\"\"\"\n","  db = dbLS[index]\n","  # t1 = ee.Date(db[\"eventDate\"]).advance(-dateRange,'month')\n","  # t2 = ee.Date(db[\"eventDate\"]).advance(dateRange,'month')\n","  t1 = dbLS[index][\"t1\"]\n","  t1Pre = ee.Date(t1).advance(-dateRange,stringMWY)\n","\n","  #filter on main geom, which contains all Polygons\n","  imagesPre = S.filterDate(t1Pre,t1).filterBounds(dbLS[index][\"geom\"]).filter(ee.Filter.eq('resolution_meters', 10))\n"," \n","\n","  imagesPreVH = getImagesVH(imagesPre)\n","  desPre = getDes(imagesPreVH)\n","  ascPre = getAsc(imagesPreVH)\n","  return ascPre,desPre\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iE9X3p3v_x6O"},"source":["def getImagesPost(S,index, dateRange,stringMWY):\n","  \"\"\"\"\n","  This function returns the post-event images, which is to say images which have happened after the landslide event happens. \n","  The input variable \"S\" refers to the image collection of Copernicus Sentinel-1 imagery from Google Earth Engine, the version which is in decibel.\n","  The input variable 'index' refers to the index of the landslide database, which region/database of the four databases is selected.\n","  These four databased are summed in the dbLS. \n","  [0] refers to Hiroshima, Japan\n","  [1] refers to Tsangpo Gorge, Chinna\n","  [2] refers to Lombok, Indonesia\n","  [3] refers to Hokkaido, Japan\n","\n","  The input variable 'dateRange' refers to the amount of time, and is given in integers.\n","  The input variable 'stringMWY' refers to the unit of time, is given in a string, and can be either :\n","  'day','month','year'.\n","  Together they make up the amount of time during which the images can be selected after the event date, e.g. \n","  'dateRange' = 1 , stringMWY = 'month' gives images during the timespan of 1 month after the event date.\n","  The event date can be found in the dbLS. The pre-event date and post-event date can differ per event, this is explained in the thesis. \n","\n","  Images of orbit with ascending and descending direction are returned separetely.\n","  \"\"\"\"\n","  \n","  db = dbLS[index]\n","  t2 = dbLS[index][\"t2\"]\n","  t2Post = ee.Date(t2).advance(dateRange,stringMWY)\n","\n","  \n","  imagesPost = S.filterDate(t2,t2Post).filterBounds(dbLS[index][\"geom\"]).filter(ee.Filter.eq('resolution_meters', 10))\n","  imagesPostVH = getImagesVH(imagesPost)\n","  desPost = getDes(imagesPostVH)\n","  ascPost = getAsc(imagesPostVH)\n","  # return ascPost\n","  return ascPost,desPost\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ye9SKwkqAqtC"},"source":["### Function to get which image is in tile"]},{"cell_type":"code","metadata":{"id":"dZVbCu_UAq4R"},"source":["def addMaskedAreaRatio(image,tile):\n","  \"\"\"\"\n","  The function returns the ratio of image in tile. It refers to the amount of tile which is covered by the image.\n","  This is necessary since some images only cover the tile for 10% or 60%,\n","   and the rest of the exported image bound bu the geometry of the tile will contain nan values.\n","  The input variable 'image' defines the image, The input variable 'tile' defines the tile.   \n","  \"\"\"\"\n","  areaNonEmpty = image.pixelArea().updateMask(image.mask()).reduceRegion(ee.Reducer.sum(),tile.geometry(),100).values().get(0)\n","  area = tile.geometry().area(1)\n","  ratioNonEmpty = ee.Number(areaNonEmpty).divide(area)\n","  #could also make ratioNonEmpty a property of the image\n","  # return image.set(ratioNonEmpty:rationNonEmpty)\n","  return ratioNonEmpty\n","\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EPBbSGaSKGvz"},"source":["### Projection image"]},{"cell_type":"code","metadata":{"id":"laYpOmX8CWya"},"source":["def getProjection_eeList(imageList):\n","  \"\"\"\"\n","  This function returns the image projection from a ee.List of image as input\n","  \"\"\"\"\n","  for i in range(len(imageList)):\n","    if (imageList[i]): #if non empty\n","      imageProjection = ee.Image(imageList[i].get(0)).select(0).projection()\n","      break\n","  return imageProjection"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MOtMvnJ1UpOn"},"source":["def getProjection_List(imageList):\n","  \"\"\"\"\n","  This function returns the image projection from a pythonic list of image as input\n","  \"\"\"\"\n","  for i in range(len(imageList)):\n","    if (imageList[i]): #if non empty\n","      imageProjection = ee.Image(imageList[i]).select(0).projection()\n","      break\n","  return imageProjection"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UiFzebVWKKz8"},"source":["### getImage Per Tile"]},{"cell_type":"code","metadata":{"id":"EY3Z4GTs3wTq"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJlWDdaHvMin"},"source":["# def add_masks_to_image(image):\n","#   #this is done on image after taking the median\n","#   #convolve makes it smoother, although this wasn't used yet in Handwerger\n","#   #the slope and curvature mask account for slope and curvate wrt to landslides.\n","  \n","#   #with smoothing\n","#   img_masked = image.convolve(smooth_S1).updateMask(mask_slope).updateMask(mask_curvature) #has to go over image instead of imcoll\n","  \n","#   #without smoothing\n","#   # img_masked = image.updateMask(mask_slope).updateMask(mask_curvature)\n","\n","#   return img_masked"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9gU8mHRUcYo"},"source":["def get_image_per_tile(S,index, date_range_num_pre,date_range_num_post,string_w_m_y,ratio_criteria):\n","  \"\"\"\"\n","  This function returns the A ratio images and their respective tile number, in a double list form.\n","  The A ratio is the log-based amplitude difference, which is defined by A ratio = A pre - A post.\n","  This is done for both images of descending and ascending direction, which are averaged together.\n","\n","\n","  The input variable \"S\" refers to the image collection of Copernicus Sentinel-1 imagery from Google Earth Engine, the version which is in decibel.\n","  The input variable 'index' refers to the index of the landslide database, which region/database of the four databases is selected.\n","  These four databased are summed in the dbLS. \n","  [0] refers to Hiroshima, Japan\n","  [1] refers to Tsangpo Gorge, Chinna\n","  [2] refers to Lombok, Indonesia\n","  [3] refers to Hokkaido, Japan\n","\n","  The input variable 'date_range_num_pre' refers to the amount of time before the event, and is given in integers.\n","  The input variable 'date_range_num_post' refers to the amount of time after the event, and is given in integers\n","  The input variable 'string_w_m_y' refers to the unit of time, is given in a string, and can be either :\n","  'day','week','month','year'.\n","\n","  Together they make up the amount of time during which the images can be selected after the event date, e.g. \n","  'date_range_num_pre' = 1 , string_w_m_y = 'month' gives images during the timespan of 1 month after the event date.\n","  The event date can be found in the dbLS. The pre-event date and post-event date can differ per event, this is explained in the thesis. \n","\n","  The input variable \"ratio_criteria\" gives the threshold ratio of which the images has to cover the tile. Recommended is to put ratio_criteria to 0.9.\n","\n","  The addition of slope and curvature masks can be done by uncommenting the '#add masks' lines,\n","  and commention the \"#without masks\" lines. Vice versa for no addition of slope and curvature masks. \n","  \"\"\"\"\n","\n","  #get pre event images and their amounts. Turn to list, necessary for func\n","  images_pre_asc,images_pre_des = getImagesPre(S,index, date_range_num_pre,string_w_m_y)\n","  #asc\n","  amount_pre_asc = images_pre_asc.size().getInfo()\n","  im_pre_asc_list = images_pre_asc.toList(amount_pre_asc)\n","  #des\n","  amount_pre_des = images_pre_des.size().getInfo()\n","  im_pre_des_list = images_pre_des.toList(amount_pre_des)\n","\n","  #get post event images and their amounts. Turn to list, necessary for func\n","  images_post_asc,images_post_des = getImagesPost(S,index, date_range_num_pre,string_w_m_y)\n","  #asc\n","  amount_post_asc = images_post_asc.size().getInfo()\n","  im_post_asc_list = images_post_asc.toList(amount_post_asc)\n","  #des\n","  amount_post_des = images_post_asc.size().getInfo()\n","  im_post_des_list = images_post_des.toList(amount_post_des)\n","\n","  #tiles\n","  tiles = dbLS[index][\"tiles\"]\n","  tiles_amount = tiles.size().getInfo()\n","  tiles_list = tiles.toList(tiles_amount)\n","\n","  #As output, both pre and post sep.\n","  # sum_pre_out = []\n","  # sum_post_out = []\n","  sum_out = [[],[]]\n","\n","\n","#Get output with double for loop, over tiles over images (pre and post sep.)\n","  for i in range(tiles_amount):\n","  # for i in range(2):\n","    # tile_nr = i + 1\n","    pre_tile_asc = []\n","    post_tile_asc = []\n","    pre_tile_des = []\n","    post_tile_des = []\n"," \n","\n","    tile = ee.Feature(tiles_list.get(i))\n","\n","    #get al images per tile for pre asc\n","    for j in range(amount_pre_asc):\n","      image = ee.Image(im_pre_asc_list.get(j))\n","      ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","      ratio = ratio_temp.getInfo()\n","      if (ratio > ratio_criteria):\n","        pre_tile_asc.append(image)\n","        #stack the im immediately in pre_tile_asc ? and then + des ... --> then possible to do (asc+des)/2\n","\n","\n","    #get al images per tile for pre des\n","    for k in range(amount_pre_des):\n","      image = ee.Image(im_pre_des_list.get(k))\n","      ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","      ratio = ratio_temp.getInfo()\n","      if (ratio > ratio_criteria):\n","        pre_tile_des.append(image)\n","\n"," \n","#get al images per tile for pre asc\n","    for l in range(amount_post_asc):\n","      image = ee.Image(im_post_asc_list.get(l))\n","      ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","      ratio = ratio_temp.getInfo()\n","      if (ratio > ratio_criteria):\n","        post_tile_asc.append(image)\n","      \n","\n","    #get al images per tile for pre des\n","    for m in range(amount_post_des):\n","      image = ee.Image(im_post_des_list.get(m))\n","      ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","      ratio = ratio_temp.getInfo()\n","      if (ratio > ratio_criteria):\n","        post_tile_des.append(image)\n","      \n","    #possbily multiple images per tile --> need to stack and average those per tile and \n","\n","    im_coll_pre_tile_asc = ee.ImageCollection(pre_tile_asc) \n","    im_coll_pre_tile_des = ee.ImageCollection(pre_tile_des)\n","    im_coll_post_tile_asc = ee.ImageCollection(post_tile_asc) \n","    im_coll_post_tile_des = ee.ImageCollection(post_tile_des) \n","\n","\n","    #add masks.\n","    # pre_tile_asc_med = add_masks_to_image(im_coll_pre_tile_asc.median())\n","    # pre_tile_des_med =  add_masks_to_image(im_coll_pre_tile_des.median())\n","    # post_tile_asc_med = add_masks_to_image(im_coll_post_tile_asc.median())\n","    # post_tile_des_med = add_masks_to_image(im_coll_post_tile_des.median())\n","\n","    #without masks\n","    pre_tile_asc_med = im_coll_pre_tile_asc.median()\n","    pre_tile_des_med =  im_coll_pre_tile_des.median()\n","    post_tile_asc_med = im_coll_post_tile_asc.median()\n","    post_tile_des_med = im_coll_post_tile_des.median()\n","    \n","\n","\n","    if (len(pre_tile_asc) != 0 and len(pre_tile_des) != 0 and len(post_tile_asc) != 0 and len(post_tile_des) != 0):\n","      diff_des = pre_tile_des_med.subtract(post_tile_des_med)\n","      diff_asc = pre_tile_asc_med.subtract(post_tile_asc_med)\n","      sum_des_asc = (diff_asc.add(diff_des)).divide(2)\n","      sum_out[0].append(i+1)\n","      sum_out[1].append(sum_des_asc)\n","\n","  \n","  return sum_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9BNRdx_hCVlN"},"source":["# def export_image_per_tile(S,index, date_range_num_pre,date_range_num_post,string_w_m_y,ratio_criteria,folder_name_x):\n","\n","#   #get pre event images and their amounts. Turn to list, necessary for func\n","#   images_pre_asc,images_pre_des = getImagesPre(S,index, date_range_num_pre,string_w_m_y)\n","#   #asc\n","#   amount_pre_asc = images_pre_asc.size().getInfo()\n","#   im_pre_asc_list = images_pre_asc.toList(amount_pre_asc)\n","#   #des\n","#   amount_pre_des = images_pre_des.size().getInfo()\n","#   im_pre_des_list = images_pre_des.toList(amount_pre_des)\n","\n","#   #get post event images and their amounts. Turn to list, necessary for func\n","#   images_post_asc,images_post_des = getImagesPost(S,index, date_range_num_pre,string_w_m_y)\n","#   #asc\n","#   amount_post_asc = images_post_asc.size().getInfo()\n","#   im_post_asc_list = images_post_asc.toList(amount_post_asc)\n","#   #des\n","#   amount_post_des = images_post_asc.size().getInfo()\n","#   im_post_des_list = images_post_des.toList(amount_post_des)\n","\n","#   #tiles\n","#   tiles = dbLS[index][\"tiles\"]\n","#   tiles_amount = tiles.size().getInfo()\n","#   tiles_list = tiles.toList(tiles_amount)\n","\n","#   #As output, both pre and post sep.\n","#   # sum_pre_out = []\n","#   # sum_post_out = []\n","#   # sum_out = [[],[]]\n","\n","\n","# #Get output with double for loop, over tiles over images (pre and post sep.)\n","#   for i in range(tiles_amount):\n","#   # for i in range(2):\n","#     # tile_nr = i + 1\n","#     pre_tile_asc = []\n","#     post_tile_asc = []\n","#     pre_tile_des = []\n","#     post_tile_des = []\n"," \n","\n","#     tile = ee.Feature(tiles_list.get(i))\n","\n","#     #get al images per tile for pre asc\n","#     for j in range(amount_pre_asc):\n","#       image = ee.Image(im_pre_asc_list.get(j))\n","#       ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","#       ratio = ratio_temp.getInfo()\n","#       if (ratio > ratio_criteria):\n","#         pre_tile_asc.append(image)\n","#         #stack the im immediately in pre_tile_asc ? and then + des ... --> then possible to do (asc+des)/2\n","\n","\n","#     #get al images per tile for pre des\n","#     for k in range(amount_pre_des):\n","#       image = ee.Image(im_pre_des_list.get(k))\n","#       ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","#       ratio = ratio_temp.getInfo()\n","#       if (ratio > ratio_criteria):\n","#         pre_tile_des.append(image)\n","\n"," \n","# #get al images per tile for pre asc\n","#     for l in range(amount_post_asc):\n","#       image = ee.Image(im_post_asc_list.get(l))\n","#       ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","#       ratio = ratio_temp.getInfo()\n","#       if (ratio > ratio_criteria):\n","#         post_tile_asc.append(image)\n","      \n","\n","#     #get al images per tile for pre des\n","#     for m in range(amount_post_des):\n","#       image = ee.Image(im_post_des_list.get(m))\n","#       ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","#       ratio = ratio_temp.getInfo()\n","#       if (ratio > ratio_criteria):\n","#         post_tile_des.append(image)\n","      \n","#     #possbily multiple images per tile --> need to stack and average those per tile and \n","\n","#     im_coll_pre_tile_asc = ee.ImageCollection(pre_tile_asc) \n","#     im_coll_pre_tile_des = ee.ImageCollection(pre_tile_des)\n","#     im_coll_post_tile_asc = ee.ImageCollection(post_tile_asc) \n","#     im_coll_post_tile_des = ee.ImageCollection(post_tile_des) \n","\n","\n","#     # add masks.\n","#     pre_tile_asc_med = add_masks_to_image(im_coll_pre_tile_asc.median())\n","#     pre_tile_des_med =  add_masks_to_image(im_coll_pre_tile_des.median())\n","#     post_tile_asc_med = add_masks_to_image(im_coll_post_tile_asc.median())\n","#     post_tile_des_med = add_masks_to_image(im_coll_post_tile_des.median())\n","    \n","\n","\n","#     if (len(pre_tile_asc) != 0 and len(pre_tile_des) != 0 and len(post_tile_asc) != 0 and len(post_tile_des) != 0):\n","#       diff_des = pre_tile_des_med.subtract(post_tile_des_med)\n","#       diff_asc = pre_tile_asc_med.subtract(post_tile_asc_med)\n","#       sum_des_asc = (diff_asc.add(diff_des)).divide(2)\n","#       # sum_out[0].append(i+1)\n","#       # sum_out[1].append(sum_des_asc)\n","#       exportOneImage_LS(index,sum_des_asc,i+1, folder_name_x)\n","\n","#       #maybe just immediately export this image... with proper tile..\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nK2dX7QOwHUJ"},"source":["def export_image_per_tile(S,index, date_range_num_pre,date_range_num_post,string_w_m_y,ratio_criteria,folder_name_x):\n","  \"\"\"\"\n","  This function exports the A ratio images.\n","  The A ratio is the log-based amplitude difference, which is defined by A ratio = A pre - A post.\n","  This is done for both images of descending and ascending direction, which are averaged together.\n","\n","\n","  The input variable \"S\" refers to the image collection of Copernicus Sentinel-1 imagery from Google Earth Engine, the version which is in decibel.\n","  The input variable 'index' refers to the index of the landslide database, which region/database of the four databases is selected.\n","  These four databased are summed in the dbLS. \n","  [0] refers to Hiroshima, Japan\n","  [1] refers to Tsangpo Gorge, Chinna\n","  [2] refers to Lombok, Indonesia\n","  [3] refers to Hokkaido, Japan\n","\n","  The input variable 'date_range_num_pre' refers to the amount of time before the event, and is given in integers.\n","  The input variable 'date_range_num_post' refers to the amount of time after the event, and is given in integers\n","  The input variable 'string_w_m_y' refers to the unit of time, is given in a string, and can be either :\n","  'day','week','month','year'.\n","\n","  Together they make up the amount of time during which the images can be selected after the event date, e.g. \n","  'date_range_num_pre' = 1 , string_w_m_y = 'month' gives images during the timespan of 1 month after the event date.\n","  The event date can be found in the dbLS. The pre-event date and post-event date can differ per event, this is explained in the thesis. \n","\n","  The input variable \"ratio_criteria\" gives the threshold ratio of which the images has to cover the tile. Recommended is to put ratio_criteria to 0.9.\n","\n","  The addition of slope and curvature masks can be done by uncommenting the '#add masks' lines,\n","  and commention the \"#without masks\" lines. Vice versa for no addition of slope and curvature masks. \n","  \"\"\"\"\n","  #get pre event images and their amounts. Turn to list, necessary for func\n","  images_pre_asc,images_pre_des = getImagesPre(S,index, date_range_num_pre,string_w_m_y)\n","  #asc\n","  amount_pre_asc = images_pre_asc.size().getInfo()\n","  im_pre_asc_list = images_pre_asc.toList(amount_pre_asc)\n","  #des\n","  amount_pre_des = images_pre_des.size().getInfo()\n","  im_pre_des_list = images_pre_des.toList(amount_pre_des)\n","\n","  #get post event images and their amounts. Turn to list, necessary for func\n","  images_post_asc,images_post_des = getImagesPost(S,index, date_range_num_pre,string_w_m_y)\n","  #asc\n","  amount_post_asc = images_post_asc.size().getInfo()\n","  im_post_asc_list = images_post_asc.toList(amount_post_asc)\n","  #des\n","  amount_post_des = images_post_asc.size().getInfo()\n","  im_post_des_list = images_post_des.toList(amount_post_des)\n","\n","  #tiles\n","  tiles = dbLS[index][\"tiles\"]\n","  tiles_amount = tiles.size().getInfo()\n","  tiles_list = tiles.toList(tiles_amount)\n","\n","  #As output, both pre and post sep.\n","  # sum_pre_out = []\n","  # sum_post_out = []\n","  # sum_out = [[],[]]\n","\n","\n","#Get output with double for loop, over tiles over images (pre and post sep.)\n","  for i in range(tiles_amount):\n","  # for i in range(2):\n","    # tile_nr = i + 1\n","    pre_tile_asc = []\n","    post_tile_asc = []\n","    pre_tile_des = []\n","    post_tile_des = []\n"," \n","\n","    tile = ee.Feature(tiles_list.get(i))\n","\n","    #get al images per tile for pre asc\n","    for j in range(amount_pre_asc):\n","      image = ee.Image(im_pre_asc_list.get(j))\n","      ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","      ratio = ratio_temp.getInfo()\n","      if (ratio > ratio_criteria):\n","        pre_tile_asc.append(image)\n","        #stack the im immediately in pre_tile_asc ? and then + des ... --> then possible to do (asc+des)/2\n","\n","\n","    #get al images per tile for pre des\n","    for k in range(amount_pre_des):\n","      image = ee.Image(im_pre_des_list.get(k))\n","      ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","      ratio = ratio_temp.getInfo()\n","      if (ratio > ratio_criteria):\n","        pre_tile_des.append(image)\n","\n"," \n","#get al images per tile for pre asc\n","    for l in range(amount_post_asc):\n","      image = ee.Image(im_post_asc_list.get(l))\n","      ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","      ratio = ratio_temp.getInfo()\n","      if (ratio > ratio_criteria):\n","        post_tile_asc.append(image)\n","      \n","\n","    #get al images per tile for pre des\n","    for m in range(amount_post_des):\n","      image = ee.Image(im_post_des_list.get(m))\n","      ratio_temp = addMaskedAreaRatio(image,tile) #could be faster it tile area is same everyhwere, to calc. that outside 2nd loop\n","      ratio = ratio_temp.getInfo()\n","      if (ratio > ratio_criteria):\n","        post_tile_des.append(image)\n","      \n","    #possbily multiple images per tile --> need to stack and average those per tile and \n","\n","    im_coll_pre_tile_asc = ee.ImageCollection(pre_tile_asc) \n","    im_coll_pre_tile_des = ee.ImageCollection(pre_tile_des)\n","    im_coll_post_tile_asc = ee.ImageCollection(post_tile_asc) \n","    im_coll_post_tile_des = ee.ImageCollection(post_tile_des) \n","\n","\n","    # add masks.\n","    pre_tile_asc_med = im_coll_pre_tile_asc.median()\n","    pre_tile_des_med =  im_coll_pre_tile_des.median()\n","    post_tile_asc_med = im_coll_post_tile_asc.median()\n","    post_tile_des_med = im_coll_post_tile_des.median()\n","    \n","\n","\n","    if (len(pre_tile_asc) != 0 and len(pre_tile_des) != 0 and len(post_tile_asc) != 0 and len(post_tile_des) != 0):\n","      diff_des = pre_tile_des_med.subtract(post_tile_des_med)\n","      diff_asc = pre_tile_asc_med.subtract(post_tile_asc_med)\n","      sum_des_asc = (diff_asc.add(diff_des)).divide(2)\n","      # sum_out[0].append(i+1)\n","      # sum_out[1].append(sum_des_asc)\n","      exportOneImage_LS(index,sum_des_asc,i+1, folder_name_x)\n","\n","      #maybe just immediately export this image... with proper tile..\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qzAhOYzQJOTQ"},"source":["### Export one image"]},{"cell_type":"code","metadata":{"id":"RhqXbg4WEL3A"},"source":["def exportOneImage_LS(index,image, tile_nr, folder_name):\n","  \"\"\"\"\n","  This function exports one image which could potentially cover landslide scars, since it covers a pre and post event time.\n","  The input variable 'index' refers to the index of the landslide database, which region/database of the four databases is selected.\n","  These four databased are summed in the dbLS. \n","  [0] refers to Hiroshima, Japan\n","  [1] refers to Tsangpo Gorge, China\n","  [2] refers to Lombok, Indonesia\n","  [3] refers to Hokkaido, Japan\n","\n","  The input variable \"image\" refers to the image to be exportedn, which is of the collection of Copernicus Sentinel-1 imagery from Google Earth Engine, \n","  the version which is in decibel.\n","\n","  The 'region' variable depicts the region which the image represents, here this is bound to a certain tile. \n","  Which tile this is, from the amount of tiles available for each region, is defined by the input variable 'tile_nr'.\n","\n","  The input varialbe 'folder_name' refers to the name of the folder in the Drive to which the exported images\n","  are to be saved. This folder is made by the function but can also be made beforehand.\n","  \n","  \"\"\"\"\n","  tiles = dbLS[index][\"tiles\"]\n","  tiles_amount = tiles.size().getInfo()\n","  tiles_list = tiles.toList(tiles_amount)\n","  image_projection = image.projection()\n","  geom_tile = ee.Feature(tiles_list.get(tile_nr)).geometry().bounds(1,image_projection)\n","  name_image = \"ImageXLS_%s\" % (tile_nr) #ImageIMAGENUMBERFROMCOLL_TILENUMBER'\n","  ee.batch.Export.image.toDrive(\n","  image = image,\n","  dimensions = \"256x256\",          \n","  region = geom_tile,\n","  description = name_image,\n","  fileNamePrefix = name_image, #necessary next to descirptioN?\n","  folder = folder_name).start()"],"execution_count":null,"outputs":[]}]}